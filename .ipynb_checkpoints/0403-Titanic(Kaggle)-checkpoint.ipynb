{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "169f72da",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Survived  Pclass  Sex  Age  Embarked  Family\n",
       "0         0       3    0  2.0         1       1\n",
       "1         1       1    1  2.0         0       1\n",
       "2         1       3    1  2.0         1       0\n",
       "3         1       1    1  2.0         1       1\n",
       "4         0       3    0  2.0         1       0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "#Raw Data Set\n",
    "train = pd.read_csv('./Data/train.csv')\n",
    "\n",
    "# display(train.head())\n",
    "\n",
    "# 제일 먼저 해야할 건.... 종속변수는 Survied\n",
    "# 독립변수 중 종속변수에 영향을 미치지 않는 것들을 찾아내야 한다. \n",
    "# 필요없는 독립 변수는 제거할 거다.\n",
    "train.drop(['PassengerId','Name','Ticket','Fare','Cabin'], axis=1 , inplace=True)\n",
    "\n",
    "# display(train.head()) # 결과 값중 문자로 되어 있는 것을 숫자로 다 바꿔줘야 한다.\n",
    "\n",
    "# 성별이 글자로 되어있다. 숫자로 변경해 줘야한다.\n",
    "my_map = { 'male' : 0,'female':1}\n",
    "train['Sex'] = train['Sex'].map(my_map) # dictional을 가지고 Series를 바꿔주는 역할을 한다. \n",
    "# display(train.head())\n",
    "\n",
    "# 가족처리\n",
    "train['Family'] = train['SibSp'] + train['Parch']\n",
    "# display(train.head())\n",
    "train.drop(['SibSp','Parch'], axis=1 , inplace=True)\n",
    "# display(train.info())\n",
    "\n",
    "# Enbarked에는 결치값이 3개 있다.\n",
    "# 지우기 보다는 값을 대체해서 사용하는게 좋다.\n",
    "# 어떻게 대체 할 것인가? => 가장 빈도가 많은 값을 찾아서 대체하는게 좋다.\n",
    "train['Embarked'] = train['Embarked'].fillna('Q')\n",
    "# display(train.info())\n",
    "my_enbarked_map ={'C':0, 'S':1 ,'Q': 2}\n",
    "train['Embarked'] = train['Embarked'].map(my_enbarked_map)\n",
    "# display(train.head())\n",
    "\n",
    "# Age는 나이인데 NaN이 너무 많다.\n",
    "# 어떻게 할까?? 삭제는 힘들다. 데이터가 너무 적어지기 때문에\n",
    "# 그럼 NaN을 다른 값으로 대체해야 한다.\n",
    "# 어떤 값으로 대체 하면 좋을까? \n",
    "train['Age'] = train['Age'].fillna(train['Age'].mean()) # train['Age'].mean()을 하면 평균값을 구할수 있다.\n",
    "# display(train.info())\n",
    "\n",
    "# 나이를 잘 살펴보니 .. 이게 연속적인 숫자값보다\n",
    "# 구간값으로 사용하면 더 좋을 거 같다.\n",
    "\n",
    "train.loc[train['Age']<8,'Age'] = 0\n",
    "train.loc[(train['Age']>= 8) & (train['Age']< 20) ,'Age'] = 1\n",
    "train.loc[(train['Age']>= 20) & (train['Age']< 65) ,'Age'] = 2\n",
    "train.loc[train['Age']>= 65,'Age'] = 3\n",
    "\n",
    "display(train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "28d6ba72",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Data Set\n",
    "x_data = train.drop('Survived', axis=1, inplace=False).values \n",
    "# print(x_data)\n",
    "t_data = train['Survived'].values.reshape(-1,1)\n",
    "# print(t_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "4b98a2ca",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/500\n",
      "23/23 [==============================] - 0s 3ms/step - loss: 0.9428 - accuracy: 0.4270 - val_loss: 0.9498 - val_accuracy: 0.4302\n",
      "Epoch 2/500\n",
      "23/23 [==============================] - 0s 947us/step - loss: 0.9343 - accuracy: 0.4270 - val_loss: 0.9393 - val_accuracy: 0.4302\n",
      "Epoch 3/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.9262 - accuracy: 0.4270 - val_loss: 0.9294 - val_accuracy: 0.4246\n",
      "Epoch 4/500\n",
      "23/23 [==============================] - 0s 973us/step - loss: 0.9183 - accuracy: 0.4270 - val_loss: 0.9200 - val_accuracy: 0.4190\n",
      "Epoch 5/500\n",
      "23/23 [==============================] - 0s 928us/step - loss: 0.9103 - accuracy: 0.4228 - val_loss: 0.9107 - val_accuracy: 0.4190\n",
      "Epoch 6/500\n",
      "23/23 [==============================] - 0s 947us/step - loss: 0.9023 - accuracy: 0.4228 - val_loss: 0.9021 - val_accuracy: 0.4190\n",
      "Epoch 7/500\n",
      "23/23 [==============================] - 0s 974us/step - loss: 0.8946 - accuracy: 0.4228 - val_loss: 0.8938 - val_accuracy: 0.4190\n",
      "Epoch 8/500\n",
      "23/23 [==============================] - 0s 950us/step - loss: 0.8873 - accuracy: 0.4242 - val_loss: 0.8858 - val_accuracy: 0.4190\n",
      "Epoch 9/500\n",
      "23/23 [==============================] - 0s 972us/step - loss: 0.8799 - accuracy: 0.4242 - val_loss: 0.8768 - val_accuracy: 0.4190\n",
      "Epoch 10/500\n",
      "23/23 [==============================] - 0s 925us/step - loss: 0.8727 - accuracy: 0.4242 - val_loss: 0.8678 - val_accuracy: 0.4190\n",
      "Epoch 11/500\n",
      "23/23 [==============================] - 0s 967us/step - loss: 0.8657 - accuracy: 0.4270 - val_loss: 0.8602 - val_accuracy: 0.4134\n",
      "Epoch 12/500\n",
      "23/23 [==============================] - 0s 899us/step - loss: 0.8588 - accuracy: 0.4312 - val_loss: 0.8512 - val_accuracy: 0.4134\n",
      "Epoch 13/500\n",
      "23/23 [==============================] - 0s 909us/step - loss: 0.8521 - accuracy: 0.4312 - val_loss: 0.8440 - val_accuracy: 0.4134\n",
      "Epoch 14/500\n",
      "23/23 [==============================] - 0s 946us/step - loss: 0.8456 - accuracy: 0.4312 - val_loss: 0.8372 - val_accuracy: 0.4134\n",
      "Epoch 15/500\n",
      "23/23 [==============================] - 0s 867us/step - loss: 0.8393 - accuracy: 0.4480 - val_loss: 0.8301 - val_accuracy: 0.5922\n",
      "Epoch 16/500\n",
      "23/23 [==============================] - 0s 897us/step - loss: 0.8328 - accuracy: 0.5702 - val_loss: 0.8220 - val_accuracy: 0.5922\n",
      "Epoch 17/500\n",
      "23/23 [==============================] - 0s 877us/step - loss: 0.8268 - accuracy: 0.5702 - val_loss: 0.8137 - val_accuracy: 0.6089\n",
      "Epoch 18/500\n",
      "23/23 [==============================] - 0s 881us/step - loss: 0.8207 - accuracy: 0.5758 - val_loss: 0.8071 - val_accuracy: 0.6089\n",
      "Epoch 19/500\n",
      "23/23 [==============================] - 0s 877us/step - loss: 0.8149 - accuracy: 0.5758 - val_loss: 0.8013 - val_accuracy: 0.6089\n",
      "Epoch 20/500\n",
      "23/23 [==============================] - 0s 894us/step - loss: 0.8091 - accuracy: 0.5758 - val_loss: 0.7957 - val_accuracy: 0.6089\n",
      "Epoch 21/500\n",
      "23/23 [==============================] - 0s 876us/step - loss: 0.8036 - accuracy: 0.5758 - val_loss: 0.7882 - val_accuracy: 0.6145\n",
      "Epoch 22/500\n",
      "23/23 [==============================] - 0s 956us/step - loss: 0.7982 - accuracy: 0.5758 - val_loss: 0.7819 - val_accuracy: 0.6145\n",
      "Epoch 23/500\n",
      "23/23 [==============================] - 0s 921us/step - loss: 0.7925 - accuracy: 0.5744 - val_loss: 0.7754 - val_accuracy: 0.6145\n",
      "Epoch 24/500\n",
      "23/23 [==============================] - 0s 905us/step - loss: 0.7869 - accuracy: 0.5744 - val_loss: 0.7686 - val_accuracy: 0.6145\n",
      "Epoch 25/500\n",
      "23/23 [==============================] - 0s 878us/step - loss: 0.7815 - accuracy: 0.5744 - val_loss: 0.7617 - val_accuracy: 0.6145\n",
      "Epoch 26/500\n",
      "23/23 [==============================] - 0s 881us/step - loss: 0.7764 - accuracy: 0.5744 - val_loss: 0.7558 - val_accuracy: 0.6145\n",
      "Epoch 27/500\n",
      "23/23 [==============================] - 0s 917us/step - loss: 0.7712 - accuracy: 0.5758 - val_loss: 0.7501 - val_accuracy: 0.6089\n",
      "Epoch 28/500\n",
      "23/23 [==============================] - 0s 883us/step - loss: 0.7660 - accuracy: 0.5758 - val_loss: 0.7436 - val_accuracy: 0.6089\n",
      "Epoch 29/500\n",
      "23/23 [==============================] - 0s 917us/step - loss: 0.7610 - accuracy: 0.5744 - val_loss: 0.7376 - val_accuracy: 0.6089\n",
      "Epoch 30/500\n",
      "23/23 [==============================] - 0s 984us/step - loss: 0.7563 - accuracy: 0.5744 - val_loss: 0.7330 - val_accuracy: 0.6145\n",
      "Epoch 31/500\n",
      "23/23 [==============================] - 0s 936us/step - loss: 0.7515 - accuracy: 0.5772 - val_loss: 0.7272 - val_accuracy: 0.6145\n",
      "Epoch 32/500\n",
      "23/23 [==============================] - 0s 995us/step - loss: 0.7469 - accuracy: 0.5787 - val_loss: 0.7217 - val_accuracy: 0.6145\n",
      "Epoch 33/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.7422 - accuracy: 0.5772 - val_loss: 0.7174 - val_accuracy: 0.6145\n",
      "Epoch 34/500\n",
      "23/23 [==============================] - 0s 833us/step - loss: 0.7380 - accuracy: 0.5787 - val_loss: 0.7118 - val_accuracy: 0.6145\n",
      "Epoch 35/500\n",
      "23/23 [==============================] - 0s 920us/step - loss: 0.7335 - accuracy: 0.5758 - val_loss: 0.7069 - val_accuracy: 0.6145\n",
      "Epoch 36/500\n",
      "23/23 [==============================] - 0s 900us/step - loss: 0.7294 - accuracy: 0.5829 - val_loss: 0.7029 - val_accuracy: 0.6145\n",
      "Epoch 37/500\n",
      "23/23 [==============================] - 0s 930us/step - loss: 0.7249 - accuracy: 0.5815 - val_loss: 0.6979 - val_accuracy: 0.6145\n",
      "Epoch 38/500\n",
      "23/23 [==============================] - 0s 901us/step - loss: 0.7207 - accuracy: 0.5787 - val_loss: 0.6933 - val_accuracy: 0.6145\n",
      "Epoch 39/500\n",
      "23/23 [==============================] - 0s 923us/step - loss: 0.7165 - accuracy: 0.5815 - val_loss: 0.6890 - val_accuracy: 0.6201\n",
      "Epoch 40/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.7123 - accuracy: 0.5801 - val_loss: 0.6838 - val_accuracy: 0.6201\n",
      "Epoch 41/500\n",
      "23/23 [==============================] - 0s 953us/step - loss: 0.7082 - accuracy: 0.5829 - val_loss: 0.6795 - val_accuracy: 0.6201\n",
      "Epoch 42/500\n",
      "23/23 [==============================] - 0s 950us/step - loss: 0.7042 - accuracy: 0.5829 - val_loss: 0.6754 - val_accuracy: 0.6201\n",
      "Epoch 43/500\n",
      "23/23 [==============================] - 0s 937us/step - loss: 0.7001 - accuracy: 0.5843 - val_loss: 0.6708 - val_accuracy: 0.6257\n",
      "Epoch 44/500\n",
      "23/23 [==============================] - 0s 928us/step - loss: 0.6962 - accuracy: 0.5843 - val_loss: 0.6664 - val_accuracy: 0.6257\n",
      "Epoch 45/500\n",
      "23/23 [==============================] - 0s 906us/step - loss: 0.6922 - accuracy: 0.5871 - val_loss: 0.6629 - val_accuracy: 0.6257\n",
      "Epoch 46/500\n",
      "23/23 [==============================] - 0s 964us/step - loss: 0.6884 - accuracy: 0.5927 - val_loss: 0.6587 - val_accuracy: 0.6536\n",
      "Epoch 47/500\n",
      "23/23 [==============================] - 0s 988us/step - loss: 0.6844 - accuracy: 0.6236 - val_loss: 0.6542 - val_accuracy: 0.6872\n",
      "Epoch 48/500\n",
      "23/23 [==============================] - 0s 935us/step - loss: 0.6809 - accuracy: 0.6292 - val_loss: 0.6493 - val_accuracy: 0.6872\n",
      "Epoch 49/500\n",
      "23/23 [==============================] - 0s 951us/step - loss: 0.6771 - accuracy: 0.6320 - val_loss: 0.6468 - val_accuracy: 0.6927\n",
      "Epoch 50/500\n",
      "23/23 [==============================] - 0s 916us/step - loss: 0.6731 - accuracy: 0.6348 - val_loss: 0.6420 - val_accuracy: 0.6872\n",
      "Epoch 51/500\n",
      "23/23 [==============================] - 0s 931us/step - loss: 0.6697 - accuracy: 0.6348 - val_loss: 0.6379 - val_accuracy: 0.6872\n",
      "Epoch 52/500\n",
      "23/23 [==============================] - 0s 906us/step - loss: 0.6662 - accuracy: 0.6348 - val_loss: 0.6340 - val_accuracy: 0.6872\n",
      "Epoch 53/500\n",
      "23/23 [==============================] - 0s 915us/step - loss: 0.6628 - accuracy: 0.6348 - val_loss: 0.6301 - val_accuracy: 0.6872\n",
      "Epoch 54/500\n",
      "23/23 [==============================] - 0s 892us/step - loss: 0.6594 - accuracy: 0.6334 - val_loss: 0.6264 - val_accuracy: 0.6872\n",
      "Epoch 55/500\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.6561 - accuracy: 0.6348 - val_loss: 0.6229 - val_accuracy: 0.6872\n",
      "Epoch 56/500\n",
      "23/23 [==============================] - 0s 947us/step - loss: 0.6528 - accuracy: 0.6320 - val_loss: 0.6195 - val_accuracy: 0.6983\n",
      "Epoch 57/500\n",
      "23/23 [==============================] - 0s 929us/step - loss: 0.6498 - accuracy: 0.6320 - val_loss: 0.6167 - val_accuracy: 0.6927\n",
      "Epoch 58/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 976us/step - loss: 0.6464 - accuracy: 0.6292 - val_loss: 0.6125 - val_accuracy: 0.6983\n",
      "Epoch 59/500\n",
      "23/23 [==============================] - 0s 917us/step - loss: 0.6431 - accuracy: 0.6334 - val_loss: 0.6096 - val_accuracy: 0.7039\n",
      "Epoch 60/500\n",
      "23/23 [==============================] - 0s 885us/step - loss: 0.6403 - accuracy: 0.6278 - val_loss: 0.6062 - val_accuracy: 0.6927\n",
      "Epoch 61/500\n",
      "23/23 [==============================] - 0s 892us/step - loss: 0.6372 - accuracy: 0.6320 - val_loss: 0.6034 - val_accuracy: 0.6927\n",
      "Epoch 62/500\n",
      "23/23 [==============================] - 0s 843us/step - loss: 0.6341 - accuracy: 0.6278 - val_loss: 0.6001 - val_accuracy: 0.6927\n",
      "Epoch 63/500\n",
      "23/23 [==============================] - 0s 863us/step - loss: 0.6313 - accuracy: 0.6292 - val_loss: 0.5963 - val_accuracy: 0.6927\n",
      "Epoch 64/500\n",
      "23/23 [==============================] - 0s 838us/step - loss: 0.6283 - accuracy: 0.6292 - val_loss: 0.5928 - val_accuracy: 0.6872\n",
      "Epoch 65/500\n",
      "23/23 [==============================] - 0s 847us/step - loss: 0.6256 - accuracy: 0.6292 - val_loss: 0.5898 - val_accuracy: 0.6872\n",
      "Epoch 66/500\n",
      "23/23 [==============================] - 0s 883us/step - loss: 0.6227 - accuracy: 0.6320 - val_loss: 0.5874 - val_accuracy: 0.6872\n",
      "Epoch 67/500\n",
      "23/23 [==============================] - 0s 898us/step - loss: 0.6199 - accuracy: 0.6334 - val_loss: 0.5850 - val_accuracy: 0.6872\n",
      "Epoch 68/500\n",
      "23/23 [==============================] - 0s 856us/step - loss: 0.6172 - accuracy: 0.6362 - val_loss: 0.5818 - val_accuracy: 0.6816\n",
      "Epoch 69/500\n",
      "23/23 [==============================] - 0s 873us/step - loss: 0.6145 - accuracy: 0.6320 - val_loss: 0.5784 - val_accuracy: 0.6983\n",
      "Epoch 70/500\n",
      "23/23 [==============================] - 0s 846us/step - loss: 0.6118 - accuracy: 0.6587 - val_loss: 0.5758 - val_accuracy: 0.7039\n",
      "Epoch 71/500\n",
      "23/23 [==============================] - 0s 877us/step - loss: 0.6093 - accuracy: 0.6685 - val_loss: 0.5737 - val_accuracy: 0.7263\n",
      "Epoch 72/500\n",
      "23/23 [==============================] - 0s 880us/step - loss: 0.6065 - accuracy: 0.6798 - val_loss: 0.5708 - val_accuracy: 0.7263\n",
      "Epoch 73/500\n",
      "23/23 [==============================] - 0s 851us/step - loss: 0.6041 - accuracy: 0.6812 - val_loss: 0.5676 - val_accuracy: 0.7318\n",
      "Epoch 74/500\n",
      "23/23 [==============================] - 0s 876us/step - loss: 0.6015 - accuracy: 0.6868 - val_loss: 0.5653 - val_accuracy: 0.7374\n",
      "Epoch 75/500\n",
      "23/23 [==============================] - 0s 864us/step - loss: 0.5990 - accuracy: 0.6882 - val_loss: 0.5631 - val_accuracy: 0.7374\n",
      "Epoch 76/500\n",
      "23/23 [==============================] - 0s 875us/step - loss: 0.5967 - accuracy: 0.6882 - val_loss: 0.5598 - val_accuracy: 0.7374\n",
      "Epoch 77/500\n",
      "23/23 [==============================] - 0s 875us/step - loss: 0.5942 - accuracy: 0.6896 - val_loss: 0.5574 - val_accuracy: 0.7374\n",
      "Epoch 78/500\n",
      "23/23 [==============================] - 0s 841us/step - loss: 0.5917 - accuracy: 0.6896 - val_loss: 0.5551 - val_accuracy: 0.7374\n",
      "Epoch 79/500\n",
      "23/23 [==============================] - 0s 843us/step - loss: 0.5896 - accuracy: 0.6910 - val_loss: 0.5532 - val_accuracy: 0.7486\n",
      "Epoch 80/500\n",
      "23/23 [==============================] - 0s 877us/step - loss: 0.5873 - accuracy: 0.6910 - val_loss: 0.5509 - val_accuracy: 0.7486\n",
      "Epoch 81/500\n",
      "23/23 [==============================] - 0s 879us/step - loss: 0.5850 - accuracy: 0.6910 - val_loss: 0.5480 - val_accuracy: 0.7430\n",
      "Epoch 82/500\n",
      "23/23 [==============================] - 0s 882us/step - loss: 0.5828 - accuracy: 0.6910 - val_loss: 0.5458 - val_accuracy: 0.7430\n",
      "Epoch 83/500\n",
      "23/23 [==============================] - 0s 866us/step - loss: 0.5807 - accuracy: 0.6910 - val_loss: 0.5431 - val_accuracy: 0.7430\n",
      "Epoch 84/500\n",
      "23/23 [==============================] - 0s 869us/step - loss: 0.5786 - accuracy: 0.6910 - val_loss: 0.5409 - val_accuracy: 0.7430\n",
      "Epoch 85/500\n",
      "23/23 [==============================] - 0s 892us/step - loss: 0.5769 - accuracy: 0.6910 - val_loss: 0.5398 - val_accuracy: 0.7486\n",
      "Epoch 86/500\n",
      "23/23 [==============================] - 0s 869us/step - loss: 0.5747 - accuracy: 0.6910 - val_loss: 0.5367 - val_accuracy: 0.7430\n",
      "Epoch 87/500\n",
      "23/23 [==============================] - 0s 840us/step - loss: 0.5726 - accuracy: 0.6910 - val_loss: 0.5349 - val_accuracy: 0.7430\n",
      "Epoch 88/500\n",
      "23/23 [==============================] - 0s 866us/step - loss: 0.5707 - accuracy: 0.6952 - val_loss: 0.5327 - val_accuracy: 0.7654\n",
      "Epoch 89/500\n",
      "23/23 [==============================] - 0s 862us/step - loss: 0.5688 - accuracy: 0.7022 - val_loss: 0.5311 - val_accuracy: 0.7709\n",
      "Epoch 90/500\n",
      "23/23 [==============================] - 0s 865us/step - loss: 0.5669 - accuracy: 0.7022 - val_loss: 0.5287 - val_accuracy: 0.7654\n",
      "Epoch 91/500\n",
      "23/23 [==============================] - 0s 852us/step - loss: 0.5651 - accuracy: 0.7191 - val_loss: 0.5269 - val_accuracy: 0.7877\n",
      "Epoch 92/500\n",
      "23/23 [==============================] - 0s 861us/step - loss: 0.5632 - accuracy: 0.7205 - val_loss: 0.5244 - val_accuracy: 0.7765\n",
      "Epoch 93/500\n",
      "23/23 [==============================] - 0s 929us/step - loss: 0.5612 - accuracy: 0.7205 - val_loss: 0.5229 - val_accuracy: 0.7989\n",
      "Epoch 94/500\n",
      "23/23 [==============================] - 0s 890us/step - loss: 0.5594 - accuracy: 0.7402 - val_loss: 0.5219 - val_accuracy: 0.8101\n",
      "Epoch 95/500\n",
      "23/23 [==============================] - 0s 872us/step - loss: 0.5578 - accuracy: 0.7514 - val_loss: 0.5195 - val_accuracy: 0.8101\n",
      "Epoch 96/500\n",
      "23/23 [==============================] - 0s 848us/step - loss: 0.5560 - accuracy: 0.7514 - val_loss: 0.5183 - val_accuracy: 0.8156\n",
      "Epoch 97/500\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.5543 - accuracy: 0.7500 - val_loss: 0.5159 - val_accuracy: 0.8156\n",
      "Epoch 98/500\n",
      "23/23 [==============================] - 0s 893us/step - loss: 0.5525 - accuracy: 0.7500 - val_loss: 0.5142 - val_accuracy: 0.8101\n",
      "Epoch 99/500\n",
      "23/23 [==============================] - 0s 894us/step - loss: 0.5508 - accuracy: 0.7584 - val_loss: 0.5126 - val_accuracy: 0.8101\n",
      "Epoch 100/500\n",
      "23/23 [==============================] - 0s 891us/step - loss: 0.5493 - accuracy: 0.7612 - val_loss: 0.5106 - val_accuracy: 0.8101\n",
      "Epoch 101/500\n",
      "23/23 [==============================] - 0s 971us/step - loss: 0.5478 - accuracy: 0.7598 - val_loss: 0.5092 - val_accuracy: 0.8101\n",
      "Epoch 102/500\n",
      "23/23 [==============================] - 0s 913us/step - loss: 0.5461 - accuracy: 0.7612 - val_loss: 0.5070 - val_accuracy: 0.8101\n",
      "Epoch 103/500\n",
      "23/23 [==============================] - 0s 967us/step - loss: 0.5447 - accuracy: 0.7612 - val_loss: 0.5058 - val_accuracy: 0.8101\n",
      "Epoch 104/500\n",
      "23/23 [==============================] - 0s 958us/step - loss: 0.5432 - accuracy: 0.7612 - val_loss: 0.5037 - val_accuracy: 0.8156\n",
      "Epoch 105/500\n",
      "23/23 [==============================] - 0s 917us/step - loss: 0.5417 - accuracy: 0.7669 - val_loss: 0.5024 - val_accuracy: 0.8212\n",
      "Epoch 106/500\n",
      "23/23 [==============================] - 0s 928us/step - loss: 0.5402 - accuracy: 0.7725 - val_loss: 0.5009 - val_accuracy: 0.8212\n",
      "Epoch 107/500\n",
      "23/23 [==============================] - 0s 948us/step - loss: 0.5390 - accuracy: 0.7739 - val_loss: 0.4993 - val_accuracy: 0.8212\n",
      "Epoch 108/500\n",
      "23/23 [==============================] - 0s 891us/step - loss: 0.5375 - accuracy: 0.7753 - val_loss: 0.4977 - val_accuracy: 0.8212\n",
      "Epoch 109/500\n",
      "23/23 [==============================] - 0s 856us/step - loss: 0.5361 - accuracy: 0.7739 - val_loss: 0.4972 - val_accuracy: 0.8212\n",
      "Epoch 110/500\n",
      "23/23 [==============================] - 0s 898us/step - loss: 0.5348 - accuracy: 0.7795 - val_loss: 0.4958 - val_accuracy: 0.8324\n",
      "Epoch 111/500\n",
      "23/23 [==============================] - 0s 881us/step - loss: 0.5334 - accuracy: 0.7809 - val_loss: 0.4947 - val_accuracy: 0.8324\n",
      "Epoch 112/500\n",
      "23/23 [==============================] - 0s 888us/step - loss: 0.5320 - accuracy: 0.7809 - val_loss: 0.4930 - val_accuracy: 0.8324\n",
      "Epoch 113/500\n",
      "23/23 [==============================] - 0s 895us/step - loss: 0.5309 - accuracy: 0.7809 - val_loss: 0.4917 - val_accuracy: 0.8324\n",
      "Epoch 114/500\n",
      "23/23 [==============================] - 0s 880us/step - loss: 0.5295 - accuracy: 0.7823 - val_loss: 0.4896 - val_accuracy: 0.8324\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 115/500\n",
      "23/23 [==============================] - 0s 903us/step - loss: 0.5283 - accuracy: 0.7809 - val_loss: 0.4883 - val_accuracy: 0.8324\n",
      "Epoch 116/500\n",
      "23/23 [==============================] - 0s 886us/step - loss: 0.5271 - accuracy: 0.7823 - val_loss: 0.4874 - val_accuracy: 0.8324\n",
      "Epoch 117/500\n",
      "23/23 [==============================] - 0s 851us/step - loss: 0.5259 - accuracy: 0.7823 - val_loss: 0.4859 - val_accuracy: 0.8324\n",
      "Epoch 118/500\n",
      "23/23 [==============================] - 0s 851us/step - loss: 0.5247 - accuracy: 0.7837 - val_loss: 0.4846 - val_accuracy: 0.8324\n",
      "Epoch 119/500\n",
      "23/23 [==============================] - 0s 897us/step - loss: 0.5237 - accuracy: 0.7809 - val_loss: 0.4843 - val_accuracy: 0.8324\n",
      "Epoch 120/500\n",
      "23/23 [==============================] - 0s 874us/step - loss: 0.5225 - accuracy: 0.7809 - val_loss: 0.4825 - val_accuracy: 0.8268\n",
      "Epoch 121/500\n",
      "23/23 [==============================] - 0s 867us/step - loss: 0.5213 - accuracy: 0.7809 - val_loss: 0.4818 - val_accuracy: 0.8324\n",
      "Epoch 122/500\n",
      "23/23 [==============================] - 0s 863us/step - loss: 0.5201 - accuracy: 0.7809 - val_loss: 0.4805 - val_accuracy: 0.8324\n",
      "Epoch 123/500\n",
      "23/23 [==============================] - 0s 859us/step - loss: 0.5190 - accuracy: 0.7809 - val_loss: 0.4792 - val_accuracy: 0.8324\n",
      "Epoch 124/500\n",
      "23/23 [==============================] - 0s 868us/step - loss: 0.5180 - accuracy: 0.7809 - val_loss: 0.4783 - val_accuracy: 0.8324\n",
      "Epoch 125/500\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.5170 - accuracy: 0.7809 - val_loss: 0.4772 - val_accuracy: 0.8324\n",
      "Epoch 126/500\n",
      "23/23 [==============================] - 0s 876us/step - loss: 0.5159 - accuracy: 0.7823 - val_loss: 0.4763 - val_accuracy: 0.8324\n",
      "Epoch 127/500\n",
      "23/23 [==============================] - 0s 862us/step - loss: 0.5148 - accuracy: 0.7823 - val_loss: 0.4751 - val_accuracy: 0.8324\n",
      "Epoch 128/500\n",
      "23/23 [==============================] - 0s 887us/step - loss: 0.5139 - accuracy: 0.7823 - val_loss: 0.4738 - val_accuracy: 0.8324\n",
      "Epoch 129/500\n",
      "23/23 [==============================] - 0s 867us/step - loss: 0.5130 - accuracy: 0.7823 - val_loss: 0.4722 - val_accuracy: 0.8324\n",
      "Epoch 130/500\n",
      "23/23 [==============================] - 0s 877us/step - loss: 0.5120 - accuracy: 0.7795 - val_loss: 0.4723 - val_accuracy: 0.8324\n",
      "Epoch 131/500\n",
      "23/23 [==============================] - 0s 850us/step - loss: 0.5109 - accuracy: 0.7781 - val_loss: 0.4708 - val_accuracy: 0.8324\n",
      "Epoch 132/500\n",
      "23/23 [==============================] - 0s 892us/step - loss: 0.5100 - accuracy: 0.7781 - val_loss: 0.4701 - val_accuracy: 0.8324\n",
      "Epoch 133/500\n",
      "23/23 [==============================] - 0s 850us/step - loss: 0.5091 - accuracy: 0.7781 - val_loss: 0.4691 - val_accuracy: 0.8324\n",
      "Epoch 134/500\n",
      "23/23 [==============================] - 0s 844us/step - loss: 0.5082 - accuracy: 0.7781 - val_loss: 0.4678 - val_accuracy: 0.8324\n",
      "Epoch 135/500\n",
      "23/23 [==============================] - 0s 836us/step - loss: 0.5074 - accuracy: 0.7795 - val_loss: 0.4666 - val_accuracy: 0.8324\n",
      "Epoch 136/500\n",
      "23/23 [==============================] - 0s 826us/step - loss: 0.5064 - accuracy: 0.7795 - val_loss: 0.4661 - val_accuracy: 0.8324\n",
      "Epoch 137/500\n",
      "23/23 [==============================] - 0s 871us/step - loss: 0.5058 - accuracy: 0.7795 - val_loss: 0.4656 - val_accuracy: 0.8324\n",
      "Epoch 138/500\n",
      "23/23 [==============================] - 0s 860us/step - loss: 0.5046 - accuracy: 0.7781 - val_loss: 0.4644 - val_accuracy: 0.8324\n",
      "Epoch 139/500\n",
      "23/23 [==============================] - 0s 853us/step - loss: 0.5040 - accuracy: 0.7781 - val_loss: 0.4636 - val_accuracy: 0.8324\n",
      "Epoch 140/500\n",
      "23/23 [==============================] - 0s 852us/step - loss: 0.5031 - accuracy: 0.7795 - val_loss: 0.4623 - val_accuracy: 0.8324\n",
      "Epoch 141/500\n",
      "23/23 [==============================] - 0s 845us/step - loss: 0.5022 - accuracy: 0.7795 - val_loss: 0.4615 - val_accuracy: 0.8324\n",
      "Epoch 142/500\n",
      "23/23 [==============================] - 0s 904us/step - loss: 0.5016 - accuracy: 0.7781 - val_loss: 0.4617 - val_accuracy: 0.8324\n",
      "Epoch 143/500\n",
      "23/23 [==============================] - 0s 930us/step - loss: 0.5008 - accuracy: 0.7781 - val_loss: 0.4602 - val_accuracy: 0.8324\n",
      "Epoch 144/500\n",
      "23/23 [==============================] - 0s 884us/step - loss: 0.4999 - accuracy: 0.7781 - val_loss: 0.4599 - val_accuracy: 0.8324\n",
      "Epoch 145/500\n",
      "23/23 [==============================] - 0s 897us/step - loss: 0.4992 - accuracy: 0.7781 - val_loss: 0.4588 - val_accuracy: 0.8324\n",
      "Epoch 146/500\n",
      "23/23 [==============================] - 0s 859us/step - loss: 0.4985 - accuracy: 0.7781 - val_loss: 0.4579 - val_accuracy: 0.8324\n",
      "Epoch 147/500\n",
      "23/23 [==============================] - 0s 832us/step - loss: 0.4978 - accuracy: 0.7781 - val_loss: 0.4571 - val_accuracy: 0.8324\n",
      "Epoch 148/500\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.4973 - accuracy: 0.7795 - val_loss: 0.4570 - val_accuracy: 0.8268\n",
      "Epoch 149/500\n",
      "23/23 [==============================] - 0s 829us/step - loss: 0.4965 - accuracy: 0.7795 - val_loss: 0.4565 - val_accuracy: 0.8268\n",
      "Epoch 150/500\n",
      "23/23 [==============================] - 0s 851us/step - loss: 0.4959 - accuracy: 0.7795 - val_loss: 0.4552 - val_accuracy: 0.8268\n",
      "Epoch 151/500\n",
      "23/23 [==============================] - 0s 850us/step - loss: 0.4953 - accuracy: 0.7893 - val_loss: 0.4550 - val_accuracy: 0.8268\n",
      "Epoch 152/500\n",
      "23/23 [==============================] - 0s 865us/step - loss: 0.4945 - accuracy: 0.7837 - val_loss: 0.4539 - val_accuracy: 0.8268\n",
      "Epoch 153/500\n",
      "23/23 [==============================] - 0s 862us/step - loss: 0.4938 - accuracy: 0.7935 - val_loss: 0.4535 - val_accuracy: 0.8268\n",
      "Epoch 154/500\n",
      "23/23 [==============================] - 0s 889us/step - loss: 0.4933 - accuracy: 0.7935 - val_loss: 0.4526 - val_accuracy: 0.8268\n",
      "Epoch 155/500\n",
      "23/23 [==============================] - 0s 910us/step - loss: 0.4928 - accuracy: 0.7809 - val_loss: 0.4516 - val_accuracy: 0.8268\n",
      "Epoch 156/500\n",
      "23/23 [==============================] - 0s 903us/step - loss: 0.4921 - accuracy: 0.7935 - val_loss: 0.4517 - val_accuracy: 0.8268\n",
      "Epoch 157/500\n",
      "23/23 [==============================] - 0s 952us/step - loss: 0.4915 - accuracy: 0.7935 - val_loss: 0.4510 - val_accuracy: 0.8268\n",
      "Epoch 158/500\n",
      "23/23 [==============================] - 0s 949us/step - loss: 0.4910 - accuracy: 0.7935 - val_loss: 0.4503 - val_accuracy: 0.8268\n",
      "Epoch 159/500\n",
      "23/23 [==============================] - 0s 926us/step - loss: 0.4904 - accuracy: 0.7935 - val_loss: 0.4499 - val_accuracy: 0.8268\n",
      "Epoch 160/500\n",
      "23/23 [==============================] - 0s 939us/step - loss: 0.4898 - accuracy: 0.7935 - val_loss: 0.4492 - val_accuracy: 0.8268\n",
      "Epoch 161/500\n",
      "23/23 [==============================] - 0s 956us/step - loss: 0.4892 - accuracy: 0.7935 - val_loss: 0.4486 - val_accuracy: 0.8268\n",
      "Epoch 162/500\n",
      "23/23 [==============================] - 0s 913us/step - loss: 0.4887 - accuracy: 0.7949 - val_loss: 0.4476 - val_accuracy: 0.8268\n",
      "Epoch 163/500\n",
      "23/23 [==============================] - 0s 925us/step - loss: 0.4881 - accuracy: 0.7949 - val_loss: 0.4472 - val_accuracy: 0.8268\n",
      "Epoch 164/500\n",
      "23/23 [==============================] - 0s 944us/step - loss: 0.4875 - accuracy: 0.7935 - val_loss: 0.4468 - val_accuracy: 0.8268\n",
      "Epoch 165/500\n",
      "23/23 [==============================] - 0s 934us/step - loss: 0.4871 - accuracy: 0.7935 - val_loss: 0.4462 - val_accuracy: 0.8268\n",
      "Epoch 166/500\n",
      "23/23 [==============================] - 0s 953us/step - loss: 0.4866 - accuracy: 0.7935 - val_loss: 0.4458 - val_accuracy: 0.8268\n",
      "Epoch 167/500\n",
      "23/23 [==============================] - 0s 911us/step - loss: 0.4862 - accuracy: 0.7935 - val_loss: 0.4448 - val_accuracy: 0.8268\n",
      "Epoch 168/500\n",
      "23/23 [==============================] - 0s 919us/step - loss: 0.4856 - accuracy: 0.7935 - val_loss: 0.4446 - val_accuracy: 0.8268\n",
      "Epoch 169/500\n",
      "23/23 [==============================] - 0s 899us/step - loss: 0.4853 - accuracy: 0.7949 - val_loss: 0.4433 - val_accuracy: 0.8268\n",
      "Epoch 170/500\n",
      "23/23 [==============================] - 0s 896us/step - loss: 0.4847 - accuracy: 0.7935 - val_loss: 0.4433 - val_accuracy: 0.8268\n",
      "Epoch 171/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 973us/step - loss: 0.4843 - accuracy: 0.7935 - val_loss: 0.4425 - val_accuracy: 0.8268\n",
      "Epoch 172/500\n",
      "23/23 [==============================] - 0s 939us/step - loss: 0.4839 - accuracy: 0.7978 - val_loss: 0.4426 - val_accuracy: 0.8268\n",
      "Epoch 173/500\n",
      "23/23 [==============================] - 0s 900us/step - loss: 0.4832 - accuracy: 0.7992 - val_loss: 0.4418 - val_accuracy: 0.8268\n",
      "Epoch 174/500\n",
      "23/23 [==============================] - 0s 933us/step - loss: 0.4828 - accuracy: 0.7992 - val_loss: 0.4414 - val_accuracy: 0.8268\n",
      "Epoch 175/500\n",
      "23/23 [==============================] - 0s 928us/step - loss: 0.4825 - accuracy: 0.7992 - val_loss: 0.4410 - val_accuracy: 0.8268\n",
      "Epoch 176/500\n",
      "23/23 [==============================] - 0s 893us/step - loss: 0.4819 - accuracy: 0.7992 - val_loss: 0.4405 - val_accuracy: 0.8268\n",
      "Epoch 177/500\n",
      "23/23 [==============================] - 0s 938us/step - loss: 0.4817 - accuracy: 0.7992 - val_loss: 0.4399 - val_accuracy: 0.8268\n",
      "Epoch 178/500\n",
      "23/23 [==============================] - 0s 958us/step - loss: 0.4811 - accuracy: 0.7992 - val_loss: 0.4395 - val_accuracy: 0.8268\n",
      "Epoch 179/500\n",
      "23/23 [==============================] - 0s 916us/step - loss: 0.4808 - accuracy: 0.7992 - val_loss: 0.4389 - val_accuracy: 0.8268\n",
      "Epoch 180/500\n",
      "23/23 [==============================] - 0s 909us/step - loss: 0.4805 - accuracy: 0.7992 - val_loss: 0.4389 - val_accuracy: 0.8268\n",
      "Epoch 181/500\n",
      "23/23 [==============================] - 0s 900us/step - loss: 0.4800 - accuracy: 0.7992 - val_loss: 0.4387 - val_accuracy: 0.8268\n",
      "Epoch 182/500\n",
      "23/23 [==============================] - 0s 916us/step - loss: 0.4798 - accuracy: 0.7992 - val_loss: 0.4380 - val_accuracy: 0.8268\n",
      "Epoch 183/500\n",
      "23/23 [==============================] - 0s 903us/step - loss: 0.4794 - accuracy: 0.7992 - val_loss: 0.4378 - val_accuracy: 0.8268\n",
      "Epoch 184/500\n",
      "23/23 [==============================] - 0s 919us/step - loss: 0.4790 - accuracy: 0.7992 - val_loss: 0.4373 - val_accuracy: 0.8268\n",
      "Epoch 185/500\n",
      "23/23 [==============================] - 0s 886us/step - loss: 0.4787 - accuracy: 0.8006 - val_loss: 0.4373 - val_accuracy: 0.8212\n",
      "Epoch 186/500\n",
      "23/23 [==============================] - 0s 905us/step - loss: 0.4784 - accuracy: 0.7992 - val_loss: 0.4362 - val_accuracy: 0.8268\n",
      "Epoch 187/500\n",
      "23/23 [==============================] - 0s 884us/step - loss: 0.4781 - accuracy: 0.8006 - val_loss: 0.4363 - val_accuracy: 0.8212\n",
      "Epoch 188/500\n",
      "23/23 [==============================] - 0s 873us/step - loss: 0.4776 - accuracy: 0.7992 - val_loss: 0.4355 - val_accuracy: 0.8268\n",
      "Epoch 189/500\n",
      "23/23 [==============================] - 0s 864us/step - loss: 0.4773 - accuracy: 0.7992 - val_loss: 0.4350 - val_accuracy: 0.8268\n",
      "Epoch 190/500\n",
      "23/23 [==============================] - 0s 886us/step - loss: 0.4770 - accuracy: 0.7992 - val_loss: 0.4344 - val_accuracy: 0.8268\n",
      "Epoch 191/500\n",
      "23/23 [==============================] - 0s 888us/step - loss: 0.4769 - accuracy: 0.7992 - val_loss: 0.4339 - val_accuracy: 0.8268\n",
      "Epoch 192/500\n",
      "23/23 [==============================] - 0s 929us/step - loss: 0.4763 - accuracy: 0.7992 - val_loss: 0.4343 - val_accuracy: 0.8268\n",
      "Epoch 193/500\n",
      "23/23 [==============================] - 0s 957us/step - loss: 0.4761 - accuracy: 0.8006 - val_loss: 0.4344 - val_accuracy: 0.8212\n",
      "Epoch 194/500\n",
      "23/23 [==============================] - 0s 922us/step - loss: 0.4757 - accuracy: 0.8006 - val_loss: 0.4339 - val_accuracy: 0.8212\n",
      "Epoch 195/500\n",
      "23/23 [==============================] - 0s 898us/step - loss: 0.4754 - accuracy: 0.8006 - val_loss: 0.4334 - val_accuracy: 0.8212\n",
      "Epoch 196/500\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.4755 - accuracy: 0.7992 - val_loss: 0.4327 - val_accuracy: 0.8268\n",
      "Epoch 197/500\n",
      "23/23 [==============================] - 0s 919us/step - loss: 0.4748 - accuracy: 0.7992 - val_loss: 0.4326 - val_accuracy: 0.8268\n",
      "Epoch 198/500\n",
      "23/23 [==============================] - 0s 942us/step - loss: 0.4745 - accuracy: 0.8006 - val_loss: 0.4327 - val_accuracy: 0.8212\n",
      "Epoch 199/500\n",
      "23/23 [==============================] - 0s 902us/step - loss: 0.4742 - accuracy: 0.7992 - val_loss: 0.4327 - val_accuracy: 0.8212\n",
      "Epoch 200/500\n",
      "23/23 [==============================] - 0s 904us/step - loss: 0.4740 - accuracy: 0.7992 - val_loss: 0.4324 - val_accuracy: 0.8212\n",
      "Epoch 201/500\n",
      "23/23 [==============================] - 0s 941us/step - loss: 0.4736 - accuracy: 0.7992 - val_loss: 0.4318 - val_accuracy: 0.8212\n",
      "Epoch 202/500\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.4735 - accuracy: 0.7992 - val_loss: 0.4316 - val_accuracy: 0.8212\n",
      "Epoch 203/500\n",
      "23/23 [==============================] - 0s 895us/step - loss: 0.4734 - accuracy: 0.7992 - val_loss: 0.4313 - val_accuracy: 0.8212\n",
      "Epoch 204/500\n",
      "23/23 [==============================] - 0s 880us/step - loss: 0.4729 - accuracy: 0.7992 - val_loss: 0.4308 - val_accuracy: 0.8212\n",
      "Epoch 205/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4727 - accuracy: 0.7992 - val_loss: 0.4307 - val_accuracy: 0.8212\n",
      "Epoch 206/500\n",
      "23/23 [==============================] - 0s 936us/step - loss: 0.4725 - accuracy: 0.7992 - val_loss: 0.4304 - val_accuracy: 0.8212\n",
      "Epoch 207/500\n",
      "23/23 [==============================] - 0s 953us/step - loss: 0.4722 - accuracy: 0.7992 - val_loss: 0.4301 - val_accuracy: 0.8212\n",
      "Epoch 208/500\n",
      "23/23 [==============================] - 0s 906us/step - loss: 0.4720 - accuracy: 0.7992 - val_loss: 0.4298 - val_accuracy: 0.8212\n",
      "Epoch 209/500\n",
      "23/23 [==============================] - 0s 950us/step - loss: 0.4717 - accuracy: 0.7992 - val_loss: 0.4295 - val_accuracy: 0.8212\n",
      "Epoch 210/500\n",
      "23/23 [==============================] - 0s 909us/step - loss: 0.4716 - accuracy: 0.7992 - val_loss: 0.4290 - val_accuracy: 0.8212\n",
      "Epoch 211/500\n",
      "23/23 [==============================] - 0s 903us/step - loss: 0.4713 - accuracy: 0.7992 - val_loss: 0.4292 - val_accuracy: 0.8212\n",
      "Epoch 212/500\n",
      "23/23 [==============================] - 0s 868us/step - loss: 0.4711 - accuracy: 0.7992 - val_loss: 0.4289 - val_accuracy: 0.8212\n",
      "Epoch 213/500\n",
      "23/23 [==============================] - 0s 886us/step - loss: 0.4708 - accuracy: 0.7992 - val_loss: 0.4287 - val_accuracy: 0.8212\n",
      "Epoch 214/500\n",
      "23/23 [==============================] - 0s 934us/step - loss: 0.4706 - accuracy: 0.7992 - val_loss: 0.4283 - val_accuracy: 0.8212\n",
      "Epoch 215/500\n",
      "23/23 [==============================] - 0s 887us/step - loss: 0.4704 - accuracy: 0.7992 - val_loss: 0.4280 - val_accuracy: 0.8212\n",
      "Epoch 216/500\n",
      "23/23 [==============================] - 0s 859us/step - loss: 0.4703 - accuracy: 0.7992 - val_loss: 0.4275 - val_accuracy: 0.8212\n",
      "Epoch 217/500\n",
      "23/23 [==============================] - 0s 883us/step - loss: 0.4700 - accuracy: 0.7992 - val_loss: 0.4273 - val_accuracy: 0.8212\n",
      "Epoch 218/500\n",
      "23/23 [==============================] - 0s 883us/step - loss: 0.4699 - accuracy: 0.7992 - val_loss: 0.4274 - val_accuracy: 0.8212\n",
      "Epoch 219/500\n",
      "23/23 [==============================] - 0s 891us/step - loss: 0.4696 - accuracy: 0.7992 - val_loss: 0.4269 - val_accuracy: 0.8212\n",
      "Epoch 220/500\n",
      "23/23 [==============================] - 0s 858us/step - loss: 0.4695 - accuracy: 0.7992 - val_loss: 0.4264 - val_accuracy: 0.8212\n",
      "Epoch 221/500\n",
      "23/23 [==============================] - 0s 853us/step - loss: 0.4692 - accuracy: 0.7992 - val_loss: 0.4269 - val_accuracy: 0.8212\n",
      "Epoch 222/500\n",
      "23/23 [==============================] - 0s 883us/step - loss: 0.4692 - accuracy: 0.7992 - val_loss: 0.4271 - val_accuracy: 0.8212\n",
      "Epoch 223/500\n",
      "23/23 [==============================] - 0s 897us/step - loss: 0.4691 - accuracy: 0.7992 - val_loss: 0.4275 - val_accuracy: 0.8212\n",
      "Epoch 224/500\n",
      "23/23 [==============================] - 0s 844us/step - loss: 0.4689 - accuracy: 0.7992 - val_loss: 0.4267 - val_accuracy: 0.8212\n",
      "Epoch 225/500\n",
      "23/23 [==============================] - 0s 887us/step - loss: 0.4686 - accuracy: 0.7992 - val_loss: 0.4263 - val_accuracy: 0.8212\n",
      "Epoch 226/500\n",
      "23/23 [==============================] - 0s 885us/step - loss: 0.4684 - accuracy: 0.7992 - val_loss: 0.4261 - val_accuracy: 0.8212\n",
      "Epoch 227/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 889us/step - loss: 0.4682 - accuracy: 0.7992 - val_loss: 0.4261 - val_accuracy: 0.8212\n",
      "Epoch 228/500\n",
      "23/23 [==============================] - 0s 890us/step - loss: 0.4681 - accuracy: 0.7992 - val_loss: 0.4256 - val_accuracy: 0.8212\n",
      "Epoch 229/500\n",
      "23/23 [==============================] - 0s 875us/step - loss: 0.4680 - accuracy: 0.7992 - val_loss: 0.4256 - val_accuracy: 0.8212\n",
      "Epoch 230/500\n",
      "23/23 [==============================] - 0s 865us/step - loss: 0.4679 - accuracy: 0.7992 - val_loss: 0.4253 - val_accuracy: 0.8212\n",
      "Epoch 231/500\n",
      "23/23 [==============================] - 0s 871us/step - loss: 0.4682 - accuracy: 0.7992 - val_loss: 0.4261 - val_accuracy: 0.8212\n",
      "Epoch 232/500\n",
      "23/23 [==============================] - 0s 865us/step - loss: 0.4676 - accuracy: 0.7992 - val_loss: 0.4255 - val_accuracy: 0.8212\n",
      "Epoch 233/500\n",
      "23/23 [==============================] - 0s 849us/step - loss: 0.4676 - accuracy: 0.7992 - val_loss: 0.4248 - val_accuracy: 0.8212\n",
      "Epoch 234/500\n",
      "23/23 [==============================] - 0s 884us/step - loss: 0.4673 - accuracy: 0.7992 - val_loss: 0.4246 - val_accuracy: 0.8212\n",
      "Epoch 235/500\n",
      "23/23 [==============================] - 0s 885us/step - loss: 0.4671 - accuracy: 0.7992 - val_loss: 0.4245 - val_accuracy: 0.8212\n",
      "Epoch 236/500\n",
      "23/23 [==============================] - 0s 854us/step - loss: 0.4671 - accuracy: 0.7992 - val_loss: 0.4245 - val_accuracy: 0.8212\n",
      "Epoch 237/500\n",
      "23/23 [==============================] - 0s 871us/step - loss: 0.4668 - accuracy: 0.7992 - val_loss: 0.4243 - val_accuracy: 0.8212\n",
      "Epoch 238/500\n",
      "23/23 [==============================] - 0s 840us/step - loss: 0.4667 - accuracy: 0.7992 - val_loss: 0.4241 - val_accuracy: 0.8212\n",
      "Epoch 239/500\n",
      "23/23 [==============================] - 0s 866us/step - loss: 0.4666 - accuracy: 0.7992 - val_loss: 0.4237 - val_accuracy: 0.8212\n",
      "Epoch 240/500\n",
      "23/23 [==============================] - 0s 853us/step - loss: 0.4665 - accuracy: 0.7992 - val_loss: 0.4237 - val_accuracy: 0.8212\n",
      "Epoch 241/500\n",
      "23/23 [==============================] - 0s 880us/step - loss: 0.4665 - accuracy: 0.7992 - val_loss: 0.4234 - val_accuracy: 0.8212\n",
      "Epoch 242/500\n",
      "23/23 [==============================] - 0s 887us/step - loss: 0.4667 - accuracy: 0.7992 - val_loss: 0.4232 - val_accuracy: 0.8212\n",
      "Epoch 243/500\n",
      "23/23 [==============================] - 0s 903us/step - loss: 0.4664 - accuracy: 0.7992 - val_loss: 0.4238 - val_accuracy: 0.8212\n",
      "Epoch 244/500\n",
      "23/23 [==============================] - 0s 847us/step - loss: 0.4660 - accuracy: 0.7992 - val_loss: 0.4235 - val_accuracy: 0.8212\n",
      "Epoch 245/500\n",
      "23/23 [==============================] - 0s 851us/step - loss: 0.4659 - accuracy: 0.7992 - val_loss: 0.4232 - val_accuracy: 0.8212\n",
      "Epoch 246/500\n",
      "23/23 [==============================] - 0s 931us/step - loss: 0.4657 - accuracy: 0.7992 - val_loss: 0.4231 - val_accuracy: 0.8212\n",
      "Epoch 247/500\n",
      "23/23 [==============================] - 0s 893us/step - loss: 0.4657 - accuracy: 0.7992 - val_loss: 0.4232 - val_accuracy: 0.8212\n",
      "Epoch 248/500\n",
      "23/23 [==============================] - 0s 856us/step - loss: 0.4654 - accuracy: 0.7992 - val_loss: 0.4225 - val_accuracy: 0.8212\n",
      "Epoch 249/500\n",
      "23/23 [==============================] - 0s 889us/step - loss: 0.4655 - accuracy: 0.7992 - val_loss: 0.4220 - val_accuracy: 0.8212\n",
      "Epoch 250/500\n",
      "23/23 [==============================] - 0s 899us/step - loss: 0.4654 - accuracy: 0.7992 - val_loss: 0.4220 - val_accuracy: 0.8212\n",
      "Epoch 251/500\n",
      "23/23 [==============================] - 0s 903us/step - loss: 0.4652 - accuracy: 0.7992 - val_loss: 0.4220 - val_accuracy: 0.8212\n",
      "Epoch 252/500\n",
      "23/23 [==============================] - 0s 863us/step - loss: 0.4652 - accuracy: 0.7992 - val_loss: 0.4219 - val_accuracy: 0.8212\n",
      "Epoch 253/500\n",
      "23/23 [==============================] - 0s 926us/step - loss: 0.4650 - accuracy: 0.7992 - val_loss: 0.4219 - val_accuracy: 0.8212\n",
      "Epoch 254/500\n",
      "23/23 [==============================] - 0s 892us/step - loss: 0.4650 - accuracy: 0.7992 - val_loss: 0.4218 - val_accuracy: 0.8212\n",
      "Epoch 255/500\n",
      "23/23 [==============================] - 0s 868us/step - loss: 0.4649 - accuracy: 0.7992 - val_loss: 0.4219 - val_accuracy: 0.8212\n",
      "Epoch 256/500\n",
      "23/23 [==============================] - 0s 868us/step - loss: 0.4648 - accuracy: 0.7992 - val_loss: 0.4219 - val_accuracy: 0.8212\n",
      "Epoch 257/500\n",
      "23/23 [==============================] - 0s 874us/step - loss: 0.4648 - accuracy: 0.7992 - val_loss: 0.4214 - val_accuracy: 0.8212\n",
      "Epoch 258/500\n",
      "23/23 [==============================] - 0s 899us/step - loss: 0.4646 - accuracy: 0.7992 - val_loss: 0.4210 - val_accuracy: 0.8212\n",
      "Epoch 259/500\n",
      "23/23 [==============================] - 0s 908us/step - loss: 0.4646 - accuracy: 0.7992 - val_loss: 0.4211 - val_accuracy: 0.8212\n",
      "Epoch 260/500\n",
      "23/23 [==============================] - 0s 907us/step - loss: 0.4645 - accuracy: 0.7992 - val_loss: 0.4208 - val_accuracy: 0.8212\n",
      "Epoch 261/500\n",
      "23/23 [==============================] - 0s 868us/step - loss: 0.4645 - accuracy: 0.7992 - val_loss: 0.4210 - val_accuracy: 0.8212\n",
      "Epoch 262/500\n",
      "23/23 [==============================] - 0s 893us/step - loss: 0.4644 - accuracy: 0.7992 - val_loss: 0.4206 - val_accuracy: 0.8212\n",
      "Epoch 263/500\n",
      "23/23 [==============================] - 0s 837us/step - loss: 0.4645 - accuracy: 0.7992 - val_loss: 0.4210 - val_accuracy: 0.8212\n",
      "Epoch 264/500\n",
      "23/23 [==============================] - 0s 840us/step - loss: 0.4642 - accuracy: 0.7992 - val_loss: 0.4206 - val_accuracy: 0.8212\n",
      "Epoch 265/500\n",
      "23/23 [==============================] - 0s 843us/step - loss: 0.4642 - accuracy: 0.7992 - val_loss: 0.4205 - val_accuracy: 0.8212\n",
      "Epoch 266/500\n",
      "23/23 [==============================] - 0s 834us/step - loss: 0.4641 - accuracy: 0.7992 - val_loss: 0.4203 - val_accuracy: 0.8212\n",
      "Epoch 267/500\n",
      "23/23 [==============================] - 0s 867us/step - loss: 0.4639 - accuracy: 0.7992 - val_loss: 0.4210 - val_accuracy: 0.8212\n",
      "Epoch 268/500\n",
      "23/23 [==============================] - 0s 854us/step - loss: 0.4639 - accuracy: 0.7992 - val_loss: 0.4207 - val_accuracy: 0.8212\n",
      "Epoch 269/500\n",
      "23/23 [==============================] - 0s 867us/step - loss: 0.4640 - accuracy: 0.7992 - val_loss: 0.4202 - val_accuracy: 0.8212\n",
      "Epoch 270/500\n",
      "23/23 [==============================] - 0s 866us/step - loss: 0.4639 - accuracy: 0.7992 - val_loss: 0.4211 - val_accuracy: 0.8212\n",
      "Epoch 271/500\n",
      "23/23 [==============================] - 0s 893us/step - loss: 0.4638 - accuracy: 0.7992 - val_loss: 0.4209 - val_accuracy: 0.8212\n",
      "Epoch 272/500\n",
      "23/23 [==============================] - 0s 896us/step - loss: 0.4637 - accuracy: 0.7992 - val_loss: 0.4204 - val_accuracy: 0.8212\n",
      "Epoch 273/500\n",
      "23/23 [==============================] - 0s 895us/step - loss: 0.4636 - accuracy: 0.7992 - val_loss: 0.4202 - val_accuracy: 0.8212\n",
      "Epoch 274/500\n",
      "23/23 [==============================] - 0s 889us/step - loss: 0.4635 - accuracy: 0.7992 - val_loss: 0.4203 - val_accuracy: 0.8212\n",
      "Epoch 275/500\n",
      "23/23 [==============================] - 0s 901us/step - loss: 0.4634 - accuracy: 0.7992 - val_loss: 0.4199 - val_accuracy: 0.8212\n",
      "Epoch 276/500\n",
      "23/23 [==============================] - 0s 869us/step - loss: 0.4634 - accuracy: 0.7992 - val_loss: 0.4196 - val_accuracy: 0.8212\n",
      "Epoch 277/500\n",
      "23/23 [==============================] - 0s 956us/step - loss: 0.4636 - accuracy: 0.7992 - val_loss: 0.4193 - val_accuracy: 0.8212\n",
      "Epoch 278/500\n",
      "23/23 [==============================] - 0s 921us/step - loss: 0.4633 - accuracy: 0.7992 - val_loss: 0.4192 - val_accuracy: 0.8212\n",
      "Epoch 279/500\n",
      "23/23 [==============================] - 0s 890us/step - loss: 0.4632 - accuracy: 0.7992 - val_loss: 0.4193 - val_accuracy: 0.8212\n",
      "Epoch 280/500\n",
      "23/23 [==============================] - 0s 869us/step - loss: 0.4636 - accuracy: 0.7992 - val_loss: 0.4188 - val_accuracy: 0.8212\n",
      "Epoch 281/500\n",
      "23/23 [==============================] - 0s 917us/step - loss: 0.4630 - accuracy: 0.7992 - val_loss: 0.4191 - val_accuracy: 0.8212\n",
      "Epoch 282/500\n",
      "23/23 [==============================] - 0s 904us/step - loss: 0.4631 - accuracy: 0.7992 - val_loss: 0.4193 - val_accuracy: 0.8212\n",
      "Epoch 283/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 867us/step - loss: 0.4630 - accuracy: 0.7992 - val_loss: 0.4189 - val_accuracy: 0.8212\n",
      "Epoch 284/500\n",
      "23/23 [==============================] - 0s 852us/step - loss: 0.4630 - accuracy: 0.7992 - val_loss: 0.4188 - val_accuracy: 0.8212\n",
      "Epoch 285/500\n",
      "23/23 [==============================] - 0s 843us/step - loss: 0.4629 - accuracy: 0.7992 - val_loss: 0.4190 - val_accuracy: 0.8212\n",
      "Epoch 286/500\n",
      "23/23 [==============================] - 0s 837us/step - loss: 0.4631 - accuracy: 0.7992 - val_loss: 0.4196 - val_accuracy: 0.8212\n",
      "Epoch 287/500\n",
      "23/23 [==============================] - 0s 839us/step - loss: 0.4630 - accuracy: 0.7935 - val_loss: 0.4197 - val_accuracy: 0.8156\n",
      "Epoch 288/500\n",
      "23/23 [==============================] - 0s 833us/step - loss: 0.4628 - accuracy: 0.7978 - val_loss: 0.4194 - val_accuracy: 0.8212\n",
      "Epoch 289/500\n",
      "23/23 [==============================] - 0s 822us/step - loss: 0.4628 - accuracy: 0.7992 - val_loss: 0.4191 - val_accuracy: 0.8212\n",
      "Epoch 290/500\n",
      "23/23 [==============================] - 0s 848us/step - loss: 0.4627 - accuracy: 0.7992 - val_loss: 0.4187 - val_accuracy: 0.8212\n",
      "Epoch 291/500\n",
      "23/23 [==============================] - 0s 845us/step - loss: 0.4627 - accuracy: 0.7992 - val_loss: 0.4187 - val_accuracy: 0.8212\n",
      "Epoch 292/500\n",
      "23/23 [==============================] - 0s 832us/step - loss: 0.4626 - accuracy: 0.7992 - val_loss: 0.4187 - val_accuracy: 0.8212\n",
      "Epoch 293/500\n",
      "23/23 [==============================] - 0s 849us/step - loss: 0.4625 - accuracy: 0.7992 - val_loss: 0.4185 - val_accuracy: 0.8212\n",
      "Epoch 294/500\n",
      "23/23 [==============================] - 0s 826us/step - loss: 0.4626 - accuracy: 0.7992 - val_loss: 0.4181 - val_accuracy: 0.8212\n",
      "Epoch 295/500\n",
      "23/23 [==============================] - 0s 835us/step - loss: 0.4625 - accuracy: 0.7992 - val_loss: 0.4183 - val_accuracy: 0.8212\n",
      "Epoch 296/500\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.4624 - accuracy: 0.7992 - val_loss: 0.4181 - val_accuracy: 0.8212\n",
      "Epoch 297/500\n",
      "23/23 [==============================] - 0s 834us/step - loss: 0.4623 - accuracy: 0.7992 - val_loss: 0.4181 - val_accuracy: 0.8212\n",
      "Epoch 298/500\n",
      "23/23 [==============================] - 0s 838us/step - loss: 0.4625 - accuracy: 0.7992 - val_loss: 0.4177 - val_accuracy: 0.8212\n",
      "Epoch 299/500\n",
      "23/23 [==============================] - 0s 902us/step - loss: 0.4623 - accuracy: 0.7992 - val_loss: 0.4176 - val_accuracy: 0.8212\n",
      "Epoch 300/500\n",
      "23/23 [==============================] - 0s 908us/step - loss: 0.4624 - accuracy: 0.7992 - val_loss: 0.4180 - val_accuracy: 0.8212\n",
      "Epoch 301/500\n",
      "23/23 [==============================] - 0s 855us/step - loss: 0.4623 - accuracy: 0.7992 - val_loss: 0.4177 - val_accuracy: 0.8212\n",
      "Epoch 302/500\n",
      "23/23 [==============================] - 0s 853us/step - loss: 0.4622 - accuracy: 0.7992 - val_loss: 0.4174 - val_accuracy: 0.8212\n",
      "Epoch 303/500\n",
      "23/23 [==============================] - 0s 851us/step - loss: 0.4622 - accuracy: 0.7992 - val_loss: 0.4172 - val_accuracy: 0.8212\n",
      "Epoch 304/500\n",
      "23/23 [==============================] - 0s 836us/step - loss: 0.4621 - accuracy: 0.7992 - val_loss: 0.4171 - val_accuracy: 0.8212\n",
      "Epoch 305/500\n",
      "23/23 [==============================] - 0s 830us/step - loss: 0.4621 - accuracy: 0.7992 - val_loss: 0.4172 - val_accuracy: 0.8212\n",
      "Epoch 306/500\n",
      "23/23 [==============================] - 0s 854us/step - loss: 0.4620 - accuracy: 0.7992 - val_loss: 0.4173 - val_accuracy: 0.8212\n",
      "Epoch 307/500\n",
      "23/23 [==============================] - 0s 827us/step - loss: 0.4621 - accuracy: 0.7992 - val_loss: 0.4172 - val_accuracy: 0.8212\n",
      "Epoch 308/500\n",
      "23/23 [==============================] - 0s 853us/step - loss: 0.4619 - accuracy: 0.7992 - val_loss: 0.4173 - val_accuracy: 0.8212\n",
      "Epoch 309/500\n",
      "23/23 [==============================] - 0s 834us/step - loss: 0.4619 - accuracy: 0.7992 - val_loss: 0.4173 - val_accuracy: 0.8212\n",
      "Epoch 310/500\n",
      "23/23 [==============================] - 0s 817us/step - loss: 0.4620 - accuracy: 0.7992 - val_loss: 0.4175 - val_accuracy: 0.8212\n",
      "Epoch 311/500\n",
      "23/23 [==============================] - 0s 860us/step - loss: 0.4619 - accuracy: 0.7992 - val_loss: 0.4169 - val_accuracy: 0.8212\n",
      "Epoch 312/500\n",
      "23/23 [==============================] - 0s 861us/step - loss: 0.4619 - accuracy: 0.7992 - val_loss: 0.4170 - val_accuracy: 0.8212\n",
      "Epoch 313/500\n",
      "23/23 [==============================] - 0s 844us/step - loss: 0.4618 - accuracy: 0.7992 - val_loss: 0.4167 - val_accuracy: 0.8212\n",
      "Epoch 314/500\n",
      "23/23 [==============================] - 0s 813us/step - loss: 0.4618 - accuracy: 0.7992 - val_loss: 0.4168 - val_accuracy: 0.8212\n",
      "Epoch 315/500\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.4619 - accuracy: 0.7992 - val_loss: 0.4167 - val_accuracy: 0.8212\n",
      "Epoch 316/500\n",
      "23/23 [==============================] - 0s 836us/step - loss: 0.4618 - accuracy: 0.7992 - val_loss: 0.4165 - val_accuracy: 0.8212\n",
      "Epoch 317/500\n",
      "23/23 [==============================] - 0s 897us/step - loss: 0.4617 - accuracy: 0.7992 - val_loss: 0.4167 - val_accuracy: 0.8212\n",
      "Epoch 318/500\n",
      "23/23 [==============================] - 0s 880us/step - loss: 0.4616 - accuracy: 0.7992 - val_loss: 0.4169 - val_accuracy: 0.8212\n",
      "Epoch 319/500\n",
      "23/23 [==============================] - 0s 860us/step - loss: 0.4616 - accuracy: 0.7992 - val_loss: 0.4173 - val_accuracy: 0.8212\n",
      "Epoch 320/500\n",
      "23/23 [==============================] - 0s 862us/step - loss: 0.4616 - accuracy: 0.7992 - val_loss: 0.4173 - val_accuracy: 0.8212\n",
      "Epoch 321/500\n",
      "23/23 [==============================] - 0s 878us/step - loss: 0.4616 - accuracy: 0.7992 - val_loss: 0.4169 - val_accuracy: 0.8212\n",
      "Epoch 322/500\n",
      "23/23 [==============================] - 0s 877us/step - loss: 0.4615 - accuracy: 0.7992 - val_loss: 0.4168 - val_accuracy: 0.8212\n",
      "Epoch 323/500\n",
      "23/23 [==============================] - 0s 844us/step - loss: 0.4615 - accuracy: 0.7992 - val_loss: 0.4168 - val_accuracy: 0.8212\n",
      "Epoch 324/500\n",
      "23/23 [==============================] - 0s 852us/step - loss: 0.4614 - accuracy: 0.7992 - val_loss: 0.4166 - val_accuracy: 0.8212\n",
      "Epoch 325/500\n",
      "23/23 [==============================] - 0s 830us/step - loss: 0.4615 - accuracy: 0.7992 - val_loss: 0.4163 - val_accuracy: 0.8212\n",
      "Epoch 326/500\n",
      "23/23 [==============================] - 0s 843us/step - loss: 0.4614 - accuracy: 0.7992 - val_loss: 0.4162 - val_accuracy: 0.8212\n",
      "Epoch 327/500\n",
      "23/23 [==============================] - 0s 865us/step - loss: 0.4615 - accuracy: 0.7992 - val_loss: 0.4163 - val_accuracy: 0.8212\n",
      "Epoch 328/500\n",
      "23/23 [==============================] - 0s 862us/step - loss: 0.4615 - accuracy: 0.7992 - val_loss: 0.4161 - val_accuracy: 0.8212\n",
      "Epoch 329/500\n",
      "23/23 [==============================] - 0s 820us/step - loss: 0.4613 - accuracy: 0.7992 - val_loss: 0.4160 - val_accuracy: 0.8212\n",
      "Epoch 330/500\n",
      "23/23 [==============================] - 0s 861us/step - loss: 0.4613 - accuracy: 0.7992 - val_loss: 0.4161 - val_accuracy: 0.8212\n",
      "Epoch 331/500\n",
      "23/23 [==============================] - 0s 866us/step - loss: 0.4613 - accuracy: 0.7992 - val_loss: 0.4159 - val_accuracy: 0.8212\n",
      "Epoch 332/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4612 - accuracy: 0.7992 - val_loss: 0.4160 - val_accuracy: 0.8212\n",
      "Epoch 333/500\n",
      "23/23 [==============================] - 0s 906us/step - loss: 0.4612 - accuracy: 0.7992 - val_loss: 0.4163 - val_accuracy: 0.8212\n",
      "Epoch 334/500\n",
      "23/23 [==============================] - 0s 888us/step - loss: 0.4613 - accuracy: 0.7992 - val_loss: 0.4161 - val_accuracy: 0.8212\n",
      "Epoch 335/500\n",
      "23/23 [==============================] - 0s 872us/step - loss: 0.4612 - accuracy: 0.7992 - val_loss: 0.4162 - val_accuracy: 0.8212\n",
      "Epoch 336/500\n",
      "23/23 [==============================] - 0s 840us/step - loss: 0.4612 - accuracy: 0.7992 - val_loss: 0.4160 - val_accuracy: 0.8212\n",
      "Epoch 337/500\n",
      "23/23 [==============================] - 0s 862us/step - loss: 0.4611 - accuracy: 0.7992 - val_loss: 0.4160 - val_accuracy: 0.8212\n",
      "Epoch 338/500\n",
      "23/23 [==============================] - 0s 859us/step - loss: 0.4611 - accuracy: 0.7992 - val_loss: 0.4163 - val_accuracy: 0.8212\n",
      "Epoch 339/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 855us/step - loss: 0.4611 - accuracy: 0.7992 - val_loss: 0.4160 - val_accuracy: 0.8212\n",
      "Epoch 340/500\n",
      "23/23 [==============================] - 0s 857us/step - loss: 0.4610 - accuracy: 0.7992 - val_loss: 0.4160 - val_accuracy: 0.8212\n",
      "Epoch 341/500\n",
      "23/23 [==============================] - 0s 826us/step - loss: 0.4610 - accuracy: 0.7992 - val_loss: 0.4161 - val_accuracy: 0.8212\n",
      "Epoch 342/500\n",
      "23/23 [==============================] - 0s 813us/step - loss: 0.4610 - accuracy: 0.7992 - val_loss: 0.4160 - val_accuracy: 0.8212\n",
      "Epoch 343/500\n",
      "23/23 [==============================] - 0s 823us/step - loss: 0.4611 - accuracy: 0.7992 - val_loss: 0.4154 - val_accuracy: 0.8212\n",
      "Epoch 344/500\n",
      "23/23 [==============================] - 0s 805us/step - loss: 0.4609 - accuracy: 0.7992 - val_loss: 0.4153 - val_accuracy: 0.8212\n",
      "Epoch 345/500\n",
      "23/23 [==============================] - 0s 811us/step - loss: 0.4611 - accuracy: 0.7992 - val_loss: 0.4154 - val_accuracy: 0.8212\n",
      "Epoch 346/500\n",
      "23/23 [==============================] - 0s 825us/step - loss: 0.4609 - accuracy: 0.7992 - val_loss: 0.4155 - val_accuracy: 0.8212\n",
      "Epoch 347/500\n",
      "23/23 [==============================] - 0s 840us/step - loss: 0.4609 - accuracy: 0.7992 - val_loss: 0.4152 - val_accuracy: 0.8212\n",
      "Epoch 348/500\n",
      "23/23 [==============================] - 0s 859us/step - loss: 0.4608 - accuracy: 0.7992 - val_loss: 0.4156 - val_accuracy: 0.8212\n",
      "Epoch 349/500\n",
      "23/23 [==============================] - 0s 851us/step - loss: 0.4608 - accuracy: 0.7992 - val_loss: 0.4156 - val_accuracy: 0.8212\n",
      "Epoch 350/500\n",
      "23/23 [==============================] - 0s 860us/step - loss: 0.4609 - accuracy: 0.7992 - val_loss: 0.4151 - val_accuracy: 0.8212\n",
      "Epoch 351/500\n",
      "23/23 [==============================] - 0s 847us/step - loss: 0.4609 - accuracy: 0.7992 - val_loss: 0.4154 - val_accuracy: 0.8212\n",
      "Epoch 352/500\n",
      "23/23 [==============================] - 0s 841us/step - loss: 0.4608 - accuracy: 0.7992 - val_loss: 0.4150 - val_accuracy: 0.8212\n",
      "Epoch 353/500\n",
      "23/23 [==============================] - 0s 814us/step - loss: 0.4608 - accuracy: 0.7992 - val_loss: 0.4150 - val_accuracy: 0.8212\n",
      "Epoch 354/500\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.4609 - accuracy: 0.7992 - val_loss: 0.4153 - val_accuracy: 0.8212\n",
      "Epoch 355/500\n",
      "23/23 [==============================] - 0s 835us/step - loss: 0.4609 - accuracy: 0.7992 - val_loss: 0.4151 - val_accuracy: 0.8212\n",
      "Epoch 356/500\n",
      "23/23 [==============================] - 0s 834us/step - loss: 0.4609 - accuracy: 0.7992 - val_loss: 0.4154 - val_accuracy: 0.8212\n",
      "Epoch 357/500\n",
      "23/23 [==============================] - 0s 818us/step - loss: 0.4607 - accuracy: 0.7992 - val_loss: 0.4151 - val_accuracy: 0.8212\n",
      "Epoch 358/500\n",
      "23/23 [==============================] - 0s 831us/step - loss: 0.4607 - accuracy: 0.7992 - val_loss: 0.4150 - val_accuracy: 0.8212\n",
      "Epoch 359/500\n",
      "23/23 [==============================] - 0s 812us/step - loss: 0.4607 - accuracy: 0.7992 - val_loss: 0.4150 - val_accuracy: 0.8212\n",
      "Epoch 360/500\n",
      "23/23 [==============================] - 0s 815us/step - loss: 0.4607 - accuracy: 0.7992 - val_loss: 0.4152 - val_accuracy: 0.8212\n",
      "Epoch 361/500\n",
      "23/23 [==============================] - 0s 820us/step - loss: 0.4606 - accuracy: 0.7992 - val_loss: 0.4147 - val_accuracy: 0.8212\n",
      "Epoch 362/500\n",
      "23/23 [==============================] - 0s 836us/step - loss: 0.4606 - accuracy: 0.7992 - val_loss: 0.4145 - val_accuracy: 0.8212\n",
      "Epoch 363/500\n",
      "23/23 [==============================] - 0s 828us/step - loss: 0.4607 - accuracy: 0.7992 - val_loss: 0.4145 - val_accuracy: 0.8212\n",
      "Epoch 364/500\n",
      "23/23 [==============================] - 0s 844us/step - loss: 0.4612 - accuracy: 0.7992 - val_loss: 0.4151 - val_accuracy: 0.8212\n",
      "Epoch 365/500\n",
      "23/23 [==============================] - 0s 825us/step - loss: 0.4606 - accuracy: 0.7992 - val_loss: 0.4150 - val_accuracy: 0.8212\n",
      "Epoch 366/500\n",
      "23/23 [==============================] - 0s 834us/step - loss: 0.4606 - accuracy: 0.7992 - val_loss: 0.4146 - val_accuracy: 0.8212\n",
      "Epoch 367/500\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.4605 - accuracy: 0.7992 - val_loss: 0.4147 - val_accuracy: 0.8212\n",
      "Epoch 368/500\n",
      "23/23 [==============================] - 0s 839us/step - loss: 0.4606 - accuracy: 0.7992 - val_loss: 0.4145 - val_accuracy: 0.8212\n",
      "Epoch 369/500\n",
      "23/23 [==============================] - 0s 855us/step - loss: 0.4605 - accuracy: 0.7992 - val_loss: 0.4145 - val_accuracy: 0.8212\n",
      "Epoch 370/500\n",
      "23/23 [==============================] - 0s 820us/step - loss: 0.4604 - accuracy: 0.7992 - val_loss: 0.4147 - val_accuracy: 0.8212\n",
      "Epoch 371/500\n",
      "23/23 [==============================] - 0s 863us/step - loss: 0.4604 - accuracy: 0.7992 - val_loss: 0.4148 - val_accuracy: 0.8212\n",
      "Epoch 372/500\n",
      "23/23 [==============================] - 0s 846us/step - loss: 0.4605 - accuracy: 0.7992 - val_loss: 0.4145 - val_accuracy: 0.8212\n",
      "Epoch 373/500\n",
      "23/23 [==============================] - 0s 873us/step - loss: 0.4604 - accuracy: 0.7992 - val_loss: 0.4148 - val_accuracy: 0.8212\n",
      "Epoch 374/500\n",
      "23/23 [==============================] - 0s 838us/step - loss: 0.4604 - accuracy: 0.7992 - val_loss: 0.4145 - val_accuracy: 0.8212\n",
      "Epoch 375/500\n",
      "23/23 [==============================] - 0s 861us/step - loss: 0.4604 - accuracy: 0.7992 - val_loss: 0.4143 - val_accuracy: 0.8212\n",
      "Epoch 376/500\n",
      "23/23 [==============================] - 0s 869us/step - loss: 0.4604 - accuracy: 0.7992 - val_loss: 0.4142 - val_accuracy: 0.8212\n",
      "Epoch 377/500\n",
      "23/23 [==============================] - 0s 863us/step - loss: 0.4603 - accuracy: 0.7992 - val_loss: 0.4140 - val_accuracy: 0.8212\n",
      "Epoch 378/500\n",
      "23/23 [==============================] - 0s 833us/step - loss: 0.4604 - accuracy: 0.7992 - val_loss: 0.4139 - val_accuracy: 0.8212\n",
      "Epoch 379/500\n",
      "23/23 [==============================] - 0s 843us/step - loss: 0.4606 - accuracy: 0.7992 - val_loss: 0.4145 - val_accuracy: 0.8212\n",
      "Epoch 380/500\n",
      "23/23 [==============================] - 0s 817us/step - loss: 0.4602 - accuracy: 0.7992 - val_loss: 0.4143 - val_accuracy: 0.8212\n",
      "Epoch 381/500\n",
      "23/23 [==============================] - 0s 898us/step - loss: 0.4603 - accuracy: 0.7992 - val_loss: 0.4144 - val_accuracy: 0.8212\n",
      "Epoch 382/500\n",
      "23/23 [==============================] - 0s 906us/step - loss: 0.4602 - accuracy: 0.7992 - val_loss: 0.4141 - val_accuracy: 0.8212\n",
      "Epoch 383/500\n",
      "23/23 [==============================] - 0s 903us/step - loss: 0.4602 - accuracy: 0.7992 - val_loss: 0.4137 - val_accuracy: 0.8212\n",
      "Epoch 384/500\n",
      "23/23 [==============================] - 0s 858us/step - loss: 0.4603 - accuracy: 0.7992 - val_loss: 0.4135 - val_accuracy: 0.8212\n",
      "Epoch 385/500\n",
      "23/23 [==============================] - 0s 924us/step - loss: 0.4603 - accuracy: 0.7992 - val_loss: 0.4133 - val_accuracy: 0.8212\n",
      "Epoch 386/500\n",
      "23/23 [==============================] - 0s 893us/step - loss: 0.4602 - accuracy: 0.7992 - val_loss: 0.4135 - val_accuracy: 0.8212\n",
      "Epoch 387/500\n",
      "23/23 [==============================] - 0s 866us/step - loss: 0.4602 - accuracy: 0.7992 - val_loss: 0.4135 - val_accuracy: 0.8212\n",
      "Epoch 388/500\n",
      "23/23 [==============================] - 0s 875us/step - loss: 0.4603 - accuracy: 0.7992 - val_loss: 0.4132 - val_accuracy: 0.8212\n",
      "Epoch 389/500\n",
      "23/23 [==============================] - 0s 880us/step - loss: 0.4604 - accuracy: 0.7992 - val_loss: 0.4134 - val_accuracy: 0.8212\n",
      "Epoch 390/500\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.4601 - accuracy: 0.7992 - val_loss: 0.4132 - val_accuracy: 0.8212\n",
      "Epoch 391/500\n",
      "23/23 [==============================] - 0s 848us/step - loss: 0.4601 - accuracy: 0.7992 - val_loss: 0.4135 - val_accuracy: 0.8212\n",
      "Epoch 392/500\n",
      "23/23 [==============================] - 0s 928us/step - loss: 0.4601 - accuracy: 0.7992 - val_loss: 0.4134 - val_accuracy: 0.8212\n",
      "Epoch 393/500\n",
      "23/23 [==============================] - 0s 877us/step - loss: 0.4601 - accuracy: 0.7992 - val_loss: 0.4136 - val_accuracy: 0.8212\n",
      "Epoch 394/500\n",
      "23/23 [==============================] - 0s 871us/step - loss: 0.4601 - accuracy: 0.7992 - val_loss: 0.4134 - val_accuracy: 0.8212\n",
      "Epoch 395/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 875us/step - loss: 0.4600 - accuracy: 0.7992 - val_loss: 0.4137 - val_accuracy: 0.8212\n",
      "Epoch 396/500\n",
      "23/23 [==============================] - 0s 839us/step - loss: 0.4600 - accuracy: 0.7992 - val_loss: 0.4140 - val_accuracy: 0.8212\n",
      "Epoch 397/500\n",
      "23/23 [==============================] - 0s 855us/step - loss: 0.4600 - accuracy: 0.7992 - val_loss: 0.4139 - val_accuracy: 0.8212\n",
      "Epoch 398/500\n",
      "23/23 [==============================] - 0s 846us/step - loss: 0.4600 - accuracy: 0.7992 - val_loss: 0.4138 - val_accuracy: 0.8212\n",
      "Epoch 399/500\n",
      "23/23 [==============================] - 0s 831us/step - loss: 0.4603 - accuracy: 0.7992 - val_loss: 0.4134 - val_accuracy: 0.8212\n",
      "Epoch 400/500\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.4601 - accuracy: 0.7992 - val_loss: 0.4134 - val_accuracy: 0.8212\n",
      "Epoch 401/500\n",
      "23/23 [==============================] - 0s 841us/step - loss: 0.4600 - accuracy: 0.7992 - val_loss: 0.4133 - val_accuracy: 0.8212\n",
      "Epoch 402/500\n",
      "23/23 [==============================] - 0s 820us/step - loss: 0.4599 - accuracy: 0.7992 - val_loss: 0.4134 - val_accuracy: 0.8212\n",
      "Epoch 403/500\n",
      "23/23 [==============================] - 0s 829us/step - loss: 0.4602 - accuracy: 0.7992 - val_loss: 0.4130 - val_accuracy: 0.8212\n",
      "Epoch 404/500\n",
      "23/23 [==============================] - 0s 860us/step - loss: 0.4599 - accuracy: 0.7992 - val_loss: 0.4133 - val_accuracy: 0.8212\n",
      "Epoch 405/500\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.4599 - accuracy: 0.7992 - val_loss: 0.4133 - val_accuracy: 0.8212\n",
      "Epoch 406/500\n",
      "23/23 [==============================] - 0s 830us/step - loss: 0.4599 - accuracy: 0.7992 - val_loss: 0.4133 - val_accuracy: 0.8212\n",
      "Epoch 407/500\n",
      "23/23 [==============================] - 0s 841us/step - loss: 0.4599 - accuracy: 0.7992 - val_loss: 0.4130 - val_accuracy: 0.8212\n",
      "Epoch 408/500\n",
      "23/23 [==============================] - 0s 888us/step - loss: 0.4599 - accuracy: 0.7992 - val_loss: 0.4132 - val_accuracy: 0.8212\n",
      "Epoch 409/500\n",
      "23/23 [==============================] - 0s 854us/step - loss: 0.4599 - accuracy: 0.7992 - val_loss: 0.4133 - val_accuracy: 0.8212\n",
      "Epoch 410/500\n",
      "23/23 [==============================] - 0s 839us/step - loss: 0.4600 - accuracy: 0.7992 - val_loss: 0.4133 - val_accuracy: 0.8212\n",
      "Epoch 411/500\n",
      "23/23 [==============================] - 0s 832us/step - loss: 0.4598 - accuracy: 0.7992 - val_loss: 0.4132 - val_accuracy: 0.8212\n",
      "Epoch 412/500\n",
      "23/23 [==============================] - 0s 837us/step - loss: 0.4597 - accuracy: 0.7992 - val_loss: 0.4128 - val_accuracy: 0.8212\n",
      "Epoch 413/500\n",
      "23/23 [==============================] - 0s 859us/step - loss: 0.4598 - accuracy: 0.7992 - val_loss: 0.4128 - val_accuracy: 0.8212\n",
      "Epoch 414/500\n",
      "23/23 [==============================] - 0s 845us/step - loss: 0.4597 - accuracy: 0.7992 - val_loss: 0.4126 - val_accuracy: 0.8212\n",
      "Epoch 415/500\n",
      "23/23 [==============================] - 0s 860us/step - loss: 0.4597 - accuracy: 0.7992 - val_loss: 0.4123 - val_accuracy: 0.8212\n",
      "Epoch 416/500\n",
      "23/23 [==============================] - 0s 828us/step - loss: 0.4599 - accuracy: 0.7992 - val_loss: 0.4127 - val_accuracy: 0.8212\n",
      "Epoch 417/500\n",
      "23/23 [==============================] - 0s 820us/step - loss: 0.4597 - accuracy: 0.7992 - val_loss: 0.4123 - val_accuracy: 0.8212\n",
      "Epoch 418/500\n",
      "23/23 [==============================] - 0s 833us/step - loss: 0.4597 - accuracy: 0.7992 - val_loss: 0.4124 - val_accuracy: 0.8212\n",
      "Epoch 419/500\n",
      "23/23 [==============================] - 0s 847us/step - loss: 0.4598 - accuracy: 0.7992 - val_loss: 0.4125 - val_accuracy: 0.8212\n",
      "Epoch 420/500\n",
      "23/23 [==============================] - 0s 868us/step - loss: 0.4596 - accuracy: 0.7992 - val_loss: 0.4123 - val_accuracy: 0.8212\n",
      "Epoch 421/500\n",
      "23/23 [==============================] - 0s 846us/step - loss: 0.4597 - accuracy: 0.7992 - val_loss: 0.4122 - val_accuracy: 0.8212\n",
      "Epoch 422/500\n",
      "23/23 [==============================] - 0s 846us/step - loss: 0.4597 - accuracy: 0.7992 - val_loss: 0.4126 - val_accuracy: 0.8212\n",
      "Epoch 423/500\n",
      "23/23 [==============================] - 0s 864us/step - loss: 0.4596 - accuracy: 0.7992 - val_loss: 0.4123 - val_accuracy: 0.8212\n",
      "Epoch 424/500\n",
      "23/23 [==============================] - 0s 838us/step - loss: 0.4595 - accuracy: 0.7992 - val_loss: 0.4125 - val_accuracy: 0.8212\n",
      "Epoch 425/500\n",
      "23/23 [==============================] - 0s 837us/step - loss: 0.4597 - accuracy: 0.7992 - val_loss: 0.4122 - val_accuracy: 0.8212\n",
      "Epoch 426/500\n",
      "23/23 [==============================] - 0s 839us/step - loss: 0.4597 - accuracy: 0.7992 - val_loss: 0.4126 - val_accuracy: 0.8212\n",
      "Epoch 427/500\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.4596 - accuracy: 0.7992 - val_loss: 0.4128 - val_accuracy: 0.8212\n",
      "Epoch 428/500\n",
      "23/23 [==============================] - 0s 826us/step - loss: 0.4596 - accuracy: 0.7992 - val_loss: 0.4127 - val_accuracy: 0.8212\n",
      "Epoch 429/500\n",
      "23/23 [==============================] - 0s 844us/step - loss: 0.4596 - accuracy: 0.7992 - val_loss: 0.4128 - val_accuracy: 0.8212\n",
      "Epoch 430/500\n",
      "23/23 [==============================] - 0s 833us/step - loss: 0.4596 - accuracy: 0.7992 - val_loss: 0.4125 - val_accuracy: 0.8212\n",
      "Epoch 431/500\n",
      "23/23 [==============================] - 0s 820us/step - loss: 0.4595 - accuracy: 0.7992 - val_loss: 0.4124 - val_accuracy: 0.8212\n",
      "Epoch 432/500\n",
      "23/23 [==============================] - 0s 804us/step - loss: 0.4595 - accuracy: 0.7992 - val_loss: 0.4128 - val_accuracy: 0.8212\n",
      "Epoch 433/500\n",
      "23/23 [==============================] - 0s 826us/step - loss: 0.4597 - accuracy: 0.7992 - val_loss: 0.4122 - val_accuracy: 0.8212\n",
      "Epoch 434/500\n",
      "23/23 [==============================] - 0s 872us/step - loss: 0.4598 - accuracy: 0.7992 - val_loss: 0.4127 - val_accuracy: 0.8212\n",
      "Epoch 435/500\n",
      "23/23 [==============================] - 0s 852us/step - loss: 0.4594 - accuracy: 0.7992 - val_loss: 0.4124 - val_accuracy: 0.8212\n",
      "Epoch 436/500\n",
      "23/23 [==============================] - 0s 861us/step - loss: 0.4595 - accuracy: 0.7992 - val_loss: 0.4122 - val_accuracy: 0.8212\n",
      "Epoch 437/500\n",
      "23/23 [==============================] - 0s 853us/step - loss: 0.4595 - accuracy: 0.8006 - val_loss: 0.4118 - val_accuracy: 0.8212\n",
      "Epoch 438/500\n",
      "23/23 [==============================] - 0s 828us/step - loss: 0.4595 - accuracy: 0.7992 - val_loss: 0.4120 - val_accuracy: 0.8212\n",
      "Epoch 439/500\n",
      "23/23 [==============================] - 0s 831us/step - loss: 0.4595 - accuracy: 0.7992 - val_loss: 0.4118 - val_accuracy: 0.8212\n",
      "Epoch 440/500\n",
      "23/23 [==============================] - 0s 853us/step - loss: 0.4595 - accuracy: 0.7992 - val_loss: 0.4119 - val_accuracy: 0.8212\n",
      "Epoch 441/500\n",
      "23/23 [==============================] - 0s 853us/step - loss: 0.4595 - accuracy: 0.8006 - val_loss: 0.4116 - val_accuracy: 0.8212\n",
      "Epoch 442/500\n",
      "23/23 [==============================] - 0s 897us/step - loss: 0.4593 - accuracy: 0.7992 - val_loss: 0.4118 - val_accuracy: 0.8212\n",
      "Epoch 443/500\n",
      "23/23 [==============================] - 0s 862us/step - loss: 0.4594 - accuracy: 0.7992 - val_loss: 0.4117 - val_accuracy: 0.8212\n",
      "Epoch 444/500\n",
      "23/23 [==============================] - 0s 909us/step - loss: 0.4595 - accuracy: 0.7992 - val_loss: 0.4117 - val_accuracy: 0.8212\n",
      "Epoch 445/500\n",
      "23/23 [==============================] - 0s 921us/step - loss: 0.4593 - accuracy: 0.7992 - val_loss: 0.4120 - val_accuracy: 0.8212\n",
      "Epoch 446/500\n",
      "23/23 [==============================] - 0s 882us/step - loss: 0.4593 - accuracy: 0.7992 - val_loss: 0.4121 - val_accuracy: 0.8212\n",
      "Epoch 447/500\n",
      "23/23 [==============================] - 0s 881us/step - loss: 0.4593 - accuracy: 0.7992 - val_loss: 0.4120 - val_accuracy: 0.8212\n",
      "Epoch 448/500\n",
      "23/23 [==============================] - 0s 894us/step - loss: 0.4593 - accuracy: 0.7992 - val_loss: 0.4118 - val_accuracy: 0.8212\n",
      "Epoch 449/500\n",
      "23/23 [==============================] - 0s 867us/step - loss: 0.4593 - accuracy: 0.7992 - val_loss: 0.4120 - val_accuracy: 0.8212\n",
      "Epoch 450/500\n",
      "23/23 [==============================] - 0s 853us/step - loss: 0.4593 - accuracy: 0.7992 - val_loss: 0.4119 - val_accuracy: 0.8212\n",
      "Epoch 451/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 862us/step - loss: 0.4593 - accuracy: 0.7992 - val_loss: 0.4118 - val_accuracy: 0.8212\n",
      "Epoch 452/500\n",
      "23/23 [==============================] - 0s 865us/step - loss: 0.4593 - accuracy: 0.7992 - val_loss: 0.4119 - val_accuracy: 0.8212\n",
      "Epoch 453/500\n",
      "23/23 [==============================] - 0s 855us/step - loss: 0.4593 - accuracy: 0.7992 - val_loss: 0.4116 - val_accuracy: 0.8212\n",
      "Epoch 454/500\n",
      "23/23 [==============================] - 0s 851us/step - loss: 0.4593 - accuracy: 0.7992 - val_loss: 0.4118 - val_accuracy: 0.8212\n",
      "Epoch 455/500\n",
      "23/23 [==============================] - 0s 842us/step - loss: 0.4592 - accuracy: 0.7992 - val_loss: 0.4116 - val_accuracy: 0.8212\n",
      "Epoch 456/500\n",
      "23/23 [==============================] - 0s 854us/step - loss: 0.4592 - accuracy: 0.7992 - val_loss: 0.4114 - val_accuracy: 0.8212\n",
      "Epoch 457/500\n",
      "23/23 [==============================] - 0s 838us/step - loss: 0.4592 - accuracy: 0.7992 - val_loss: 0.4110 - val_accuracy: 0.8212\n",
      "Epoch 458/500\n",
      "23/23 [==============================] - 0s 819us/step - loss: 0.4592 - accuracy: 0.7992 - val_loss: 0.4113 - val_accuracy: 0.8212\n",
      "Epoch 459/500\n",
      "23/23 [==============================] - 0s 831us/step - loss: 0.4592 - accuracy: 0.7992 - val_loss: 0.4114 - val_accuracy: 0.8212\n",
      "Epoch 460/500\n",
      "23/23 [==============================] - 0s 823us/step - loss: 0.4591 - accuracy: 0.7992 - val_loss: 0.4115 - val_accuracy: 0.8212\n",
      "Epoch 461/500\n",
      "23/23 [==============================] - 0s 838us/step - loss: 0.4591 - accuracy: 0.7992 - val_loss: 0.4113 - val_accuracy: 0.8212\n",
      "Epoch 462/500\n",
      "23/23 [==============================] - 0s 814us/step - loss: 0.4592 - accuracy: 0.7992 - val_loss: 0.4113 - val_accuracy: 0.8212\n",
      "Epoch 463/500\n",
      "23/23 [==============================] - 0s 820us/step - loss: 0.4592 - accuracy: 0.7992 - val_loss: 0.4110 - val_accuracy: 0.8212\n",
      "Epoch 464/500\n",
      "23/23 [==============================] - 0s 810us/step - loss: 0.4591 - accuracy: 0.7992 - val_loss: 0.4115 - val_accuracy: 0.8212\n",
      "Epoch 465/500\n",
      "23/23 [==============================] - 0s 820us/step - loss: 0.4593 - accuracy: 0.7992 - val_loss: 0.4114 - val_accuracy: 0.8212\n",
      "Epoch 466/500\n",
      "23/23 [==============================] - 0s 809us/step - loss: 0.4591 - accuracy: 0.7992 - val_loss: 0.4111 - val_accuracy: 0.8212\n",
      "Epoch 467/500\n",
      "23/23 [==============================] - 0s 817us/step - loss: 0.4591 - accuracy: 0.7992 - val_loss: 0.4112 - val_accuracy: 0.8212\n",
      "Epoch 468/500\n",
      "23/23 [==============================] - 0s 826us/step - loss: 0.4591 - accuracy: 0.7992 - val_loss: 0.4111 - val_accuracy: 0.8212\n",
      "Epoch 469/500\n",
      "23/23 [==============================] - 0s 853us/step - loss: 0.4590 - accuracy: 0.7992 - val_loss: 0.4110 - val_accuracy: 0.8212\n",
      "Epoch 470/500\n",
      "23/23 [==============================] - 0s 816us/step - loss: 0.4590 - accuracy: 0.7992 - val_loss: 0.4109 - val_accuracy: 0.8212\n",
      "Epoch 471/500\n",
      "23/23 [==============================] - 0s 810us/step - loss: 0.4590 - accuracy: 0.7992 - val_loss: 0.4109 - val_accuracy: 0.8212\n",
      "Epoch 472/500\n",
      "23/23 [==============================] - 0s 846us/step - loss: 0.4592 - accuracy: 0.7992 - val_loss: 0.4106 - val_accuracy: 0.8212\n",
      "Epoch 473/500\n",
      "23/23 [==============================] - 0s 810us/step - loss: 0.4590 - accuracy: 0.7992 - val_loss: 0.4109 - val_accuracy: 0.8212\n",
      "Epoch 474/500\n",
      "23/23 [==============================] - 0s 833us/step - loss: 0.4590 - accuracy: 0.7992 - val_loss: 0.4109 - val_accuracy: 0.8212\n",
      "Epoch 475/500\n",
      "23/23 [==============================] - 0s 875us/step - loss: 0.4590 - accuracy: 0.7992 - val_loss: 0.4110 - val_accuracy: 0.8212\n",
      "Epoch 476/500\n",
      "23/23 [==============================] - 0s 861us/step - loss: 0.4591 - accuracy: 0.7992 - val_loss: 0.4112 - val_accuracy: 0.8212\n",
      "Epoch 477/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4590 - accuracy: 0.7992 - val_loss: 0.4106 - val_accuracy: 0.8212\n",
      "Epoch 478/500\n",
      "23/23 [==============================] - 0s 893us/step - loss: 0.4590 - accuracy: 0.7992 - val_loss: 0.4108 - val_accuracy: 0.8212\n",
      "Epoch 479/500\n",
      "23/23 [==============================] - 0s 851us/step - loss: 0.4590 - accuracy: 0.7992 - val_loss: 0.4108 - val_accuracy: 0.8212\n",
      "Epoch 480/500\n",
      "23/23 [==============================] - 0s 838us/step - loss: 0.4590 - accuracy: 0.7992 - val_loss: 0.4103 - val_accuracy: 0.8212\n",
      "Epoch 481/500\n",
      "23/23 [==============================] - 0s 855us/step - loss: 0.4591 - accuracy: 0.7992 - val_loss: 0.4106 - val_accuracy: 0.8212\n",
      "Epoch 482/500\n",
      "23/23 [==============================] - 0s 857us/step - loss: 0.4590 - accuracy: 0.7992 - val_loss: 0.4103 - val_accuracy: 0.8212\n",
      "Epoch 483/500\n",
      "23/23 [==============================] - 0s 871us/step - loss: 0.4589 - accuracy: 0.7992 - val_loss: 0.4102 - val_accuracy: 0.8212\n",
      "Epoch 484/500\n",
      "23/23 [==============================] - 0s 1ms/step - loss: 0.4589 - accuracy: 0.7992 - val_loss: 0.4106 - val_accuracy: 0.8212\n",
      "Epoch 485/500\n",
      "23/23 [==============================] - 0s 904us/step - loss: 0.4589 - accuracy: 0.7992 - val_loss: 0.4105 - val_accuracy: 0.8212\n",
      "Epoch 486/500\n",
      "23/23 [==============================] - 0s 862us/step - loss: 0.4589 - accuracy: 0.7992 - val_loss: 0.4106 - val_accuracy: 0.8212\n",
      "Epoch 487/500\n",
      "23/23 [==============================] - 0s 869us/step - loss: 0.4588 - accuracy: 0.7992 - val_loss: 0.4107 - val_accuracy: 0.8212\n",
      "Epoch 488/500\n",
      "23/23 [==============================] - 0s 906us/step - loss: 0.4590 - accuracy: 0.7992 - val_loss: 0.4107 - val_accuracy: 0.8212\n",
      "Epoch 489/500\n",
      "23/23 [==============================] - 0s 899us/step - loss: 0.4591 - accuracy: 0.7992 - val_loss: 0.4109 - val_accuracy: 0.8212\n",
      "Epoch 490/500\n",
      "23/23 [==============================] - 0s 898us/step - loss: 0.4587 - accuracy: 0.7992 - val_loss: 0.4104 - val_accuracy: 0.8212\n",
      "Epoch 491/500\n",
      "23/23 [==============================] - 0s 863us/step - loss: 0.4588 - accuracy: 0.8006 - val_loss: 0.4102 - val_accuracy: 0.8212\n",
      "Epoch 492/500\n",
      "23/23 [==============================] - 0s 845us/step - loss: 0.4588 - accuracy: 0.7992 - val_loss: 0.4099 - val_accuracy: 0.8268\n",
      "Epoch 493/500\n",
      "23/23 [==============================] - 0s 876us/step - loss: 0.4587 - accuracy: 0.7992 - val_loss: 0.4103 - val_accuracy: 0.8212\n",
      "Epoch 494/500\n",
      "23/23 [==============================] - 0s 880us/step - loss: 0.4590 - accuracy: 0.7992 - val_loss: 0.4107 - val_accuracy: 0.8212\n",
      "Epoch 495/500\n",
      "23/23 [==============================] - 0s 870us/step - loss: 0.4588 - accuracy: 0.7992 - val_loss: 0.4104 - val_accuracy: 0.8212\n",
      "Epoch 496/500\n",
      "23/23 [==============================] - 0s 898us/step - loss: 0.4588 - accuracy: 0.7992 - val_loss: 0.4102 - val_accuracy: 0.8212\n",
      "Epoch 497/500\n",
      "23/23 [==============================] - 0s 925us/step - loss: 0.4587 - accuracy: 0.8006 - val_loss: 0.4102 - val_accuracy: 0.8212\n",
      "Epoch 498/500\n",
      "23/23 [==============================] - 0s 912us/step - loss: 0.4588 - accuracy: 0.8006 - val_loss: 0.4101 - val_accuracy: 0.8212\n",
      "Epoch 499/500\n",
      "23/23 [==============================] - 0s 876us/step - loss: 0.4588 - accuracy: 0.7992 - val_loss: 0.4102 - val_accuracy: 0.8212\n",
      "Epoch 500/500\n",
      "23/23 [==============================] - 0s 888us/step - loss: 0.4588 - accuracy: 0.7992 - val_loss: 0.4101 - val_accuracy: 0.8212\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x161b9f820>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "# Model\n",
    "model = Sequential()\n",
    "\n",
    "# Model에 Layer 추가\n",
    "model.add(Flatten(input_shape=(5,)))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    "\n",
    "#Model 설정\n",
    "model.compile(optimizer=Adam(learning_rate=1e-3),\n",
    "                            loss='binary_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "              \n",
    "# Model 학습\n",
    "model.fit(x_data, \n",
    "          t_data, \n",
    "          epochs=500, \n",
    "          validation_split=0.2,\n",
    "          verbose=1)\n",
    "              "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "07965a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 완성했다.\n",
    "# Kaggle에서 제공해준 .. test.csv를 이용해서 prediction을 해야한다.\n",
    "# test.csv를 읽어들여서 이 데이터를 다시 변형시켜야 한다.\n",
    "# machine learning model에 입력으로 넣어야 하기 때문이다.\n",
    "# 결과가 나오면 이쁘게 결과 파일을 만들어서 kaggle에 제출해서 \n",
    "# 우리 모델의 정확도를 측정받으면 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ca8c373c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>Embarked</th>\n",
       "      <th>Family</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Sex  Age  Embarked  Family\n",
       "0       3    0  2.0         2       0\n",
       "1       3    1  2.0         1       1\n",
       "2       2    0  2.0         2       0\n",
       "3       3    0  2.0         1       0\n",
       "4       3    1  2.0         1       2"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test = pd.read_csv('./Data/test.csv')\n",
    "# print(test.info())\n",
    "test.drop(['PassengerId','Name','Ticket','Fare','Cabin'], axis=1 , inplace=True)\n",
    "# display(test.head())\n",
    "\n",
    "my_map = { 'male' : 0,'female':1}\n",
    "test['Sex'] = test['Sex'].map(my_map) # dictional을 가지고 Series를 바꿔주는 역할을 한다. \n",
    "# display(train.head())\n",
    "\n",
    "# 가족처리\n",
    "test['Family'] = test['SibSp'] + test['Parch']\n",
    "# display(train.head())\n",
    "test.drop(['SibSp','Parch'], axis=1 , inplace=True)\n",
    "# display(train.info())\n",
    "\n",
    "# Enbarked에는 결치값이 3개 있다.\n",
    "# 지우기 보다는 값을 대체해서 사용하는게 좋다.\n",
    "# 어떻게 대체 할 것인가? => 가장 빈도가 많은 값을 찾아서 대체하는게 좋다.\n",
    "test['Embarked'] = test['Embarked'].fillna('Q')\n",
    "# display(train.info())\n",
    "my_enbarked_map ={'C':0, 'S':1 ,'Q': 2}\n",
    "test['Embarked'] = test['Embarked'].map(my_enbarked_map)\n",
    "# display(test.head())\n",
    "\n",
    "test['Age'] = test['Age'].fillna(test['Age'].mean()) # train['Age'].mean()을 하면 평균값을 구할수 있다.\n",
    "# display(train.info())\n",
    "\n",
    "# 나이를 잘 살펴보니 .. 이게 연속적인 숫자값보다\n",
    "# 구간값으로 사용하면 더 좋을 거 같다.\n",
    "\n",
    "test.loc[test['Age']<8,'Age'] = 0\n",
    "test.loc[(test['Age']>= 8) & (test['Age']< 20) ,'Age'] = 1\n",
    "test.loc[(test['Age']>= 20) & (test['Age']< 65) ,'Age'] = 2\n",
    "test.loc[test['Age']>= 65,'Age'] = 3\n",
    "\n",
    "display(test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91c4453d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:data_env] *",
   "language": "python",
   "name": "conda-env-data_env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
